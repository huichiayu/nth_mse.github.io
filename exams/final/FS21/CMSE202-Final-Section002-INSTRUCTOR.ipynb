{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER (for making sure this gets removed)\n",
    "\n",
    "# Grading Rubric (50 points total)\n",
    "\n",
    "## Part 1 (2 points)\n",
    "\n",
    "* **Question 1.1** (2 points):\n",
    "  * 1 point for creating the GitHub repository directory\n",
    "  * 1 point for correctly writing the cloning command\n",
    "\n",
    "## Part 2 (16 points)\n",
    "\n",
    "* **Question 2.1** (3 points):\n",
    "  * 1 point for downloading the data\n",
    "  * 1 point for reading the .csv file\n",
    "  * 1 point for displaying the first few lines\n",
    "* **Question 2.2** (4 points):\n",
    "  * 1 point for creating an undirected graph (`nx.Graph()`)\n",
    "  * 1 point for iterating over the dataset\n",
    "  * 1 point for adding edges for every line in the .csv file between `Source` and `Target`\n",
    "  * 1 point for those edges having no weights\n",
    "* **Question 2.3** (5 points):\n",
    "  * 1 point for making a large figure (bigger than the matplotlib default)\n",
    "  * 2 points for drawing the graph\n",
    "  * 1 point for adding labels to nodes\n",
    "  * 1 point for changing the color of one node/setting colors\n",
    "* **Question 2.4** (1 point):\n",
    "  * 1 point for finding the right function\n",
    "* **Question 2.5** (1 point):\n",
    "  * 1 point for finding the right function\n",
    "* **Question 2.6** (1 point):\n",
    "  * 1 point for finding the right function\n",
    "* **Question 2.7** (1 point):\n",
    "  * 1 point for finding the right function\n",
    "\n",
    "## Part 3 (16 points)\n",
    "\n",
    "* **Question 3.1** (2 points):\n",
    "  * 1 point for downloading the data\n",
    "  * 1 point for reading the .csv file\n",
    "* **Question 3.2** (3 points):\n",
    "  * 1 point for selecting the `labels` data (the `Weights` column only)\n",
    "  * 1 point for selecting the `features` data (all of the other columns)\n",
    "  * 1 point for printing the first few lines of both of them\n",
    "* **Question 3.3** (2 points):\n",
    "  * 1 point for adding the column\n",
    "  * 1 point for printing `features_const`\n",
    "* **Question 3.4** (3 points):\n",
    "  * 2 points for performing the fit\n",
    "  * 1 point for printing the summary\n",
    "* **Question 3.5** (2 points):\n",
    "  * 2 points for an explanation\n",
    "* **Question 3.6** (2 points):\n",
    "  * 1 point for selecting the new features\n",
    "  * 1 point for running the fit again\n",
    "* **Question 3.7** (2 points):\n",
    "  * 1 point for explaining which fit summary parameter was used\n",
    "  * 1 point for pointing out that the fit quality doesn't change much\n",
    "\n",
    "## Part 4 (16 points)\n",
    "\n",
    "* **Question 4.1** (1 points):\n",
    "  * 1 point for loading the dataset and displaying the first few lines\n",
    "* **Question 4.2** (3 points):\n",
    "  * 1 point for creating the correct `labels` and `features\n",
    "  * 1 point for creating the train-test split\n",
    "  * 1 point for using the correct `train_size` and `random_state`\n",
    "* **Question 4.3** (6 points):\n",
    "  * 1 point for fitting the SVC\n",
    "  * 1 point for using a linear kernel and C=1\n",
    "  * 1 point for using the training set for fitting (not the full set or the testing set)\n",
    "  * 1 point for predicting\n",
    "  * 1 point for predicting on the testing set (not the training set or full set)\n",
    "  * 1 point for printing both the `confusion_matrix` and the `classification_report`\n",
    "* **Question 4.4** (3 points):\n",
    "  * 1 point for \"confusion matrix is mostly diagonal, only a few off-diagonal elements\"\n",
    "  * 1 point for \"looks to be a good classifier\"\n",
    "  * 1 point for the quantity used to judge the classifier (e.g. accuracy)\n",
    "* **Question 4.5** (3 points):\n",
    "  * 1 point for explaining labels and features\n",
    "  * 2 points for explaining why we need training and testing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: right;\"> &#9989; Put your name here</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Final (Section 002 - Fall 2021)\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed having now finished CMSE 202. In particular, you'll be committing and pushing repository changes to a GitHub repository, working with data to build a network graph, performing regression analysis, and classifying data using a machine learning classifier. You should find that you have all of the skills necessary to complete this exam having completed the second half of CMSE 202!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. Once you've read through it, you'll probably want to make sure you do Part 1 first to ensure that your GitHub repository is working correctly. Let your instructor know right away if you run into issues!\n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. **However**: The use of any person-to-person communication software is absolutely not acceptable. If you are seen accessing your email, using a chat program (e.g. Slack), or any sort of collaborative cloud storage or document software (e.g. Google Documents), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**Keep your eyes on your screen!** Unfortunately, there isn't enough space in the room for everyone to sit at their own table so please do your best to keep your eyes on your own screen. This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero. If you're completing the exam virtually, the same standards of academic integrity apply!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 0: Academic integrity statement\n",
    "\n",
    "Read the following statement and edit the markdown text to put your name in the statement. This is your commitment to doing your own authentic work on this exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I, **INSERT NAME HERE**, affirm that this exam represents my own authetic work, without the use of any unpermitted aids or resources or person-to-person communication. I understand that this exam an an opportunity to showcase my own progress in developing and improving my computational skills and have done my best to demonstrate those skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Add to your Git repository to track your progress on your exam (2 points)\n",
    "\n",
    "Before you get to far along in the exam, you're going to add it to the `cmse202-f21-turnin` repository you created in class so that you can track your progress on the exam and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "1. Navigate to your `cmse202-f21-turnin` repository and create a new directory called `final`.\n",
    "2. Move this notebook into that **new directory** in your repository, then **add it and commit it to your repository**.\n",
    "1. Finally, to test that everything is working, \"git push\" the file so that it ends up in your GitHub repository.\n",
    "\n",
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" respository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the noteobok, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-f21-turnin`\" repository inside the `final` directory that you just created.  Periodically, **you'll be asked to commit your changes to the repository and push them to the remote GitHub location**. Of course, you can always commit your changes more often than that, if you wish.  It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the project for a bit.\n",
    "\n",
    "&#9989; **Question 1.1 (2 point)**: **Do this**: Before you move on, put the command that your instructor should run to clone your repository in the markdown cell below. Also make sure that you created the directory and pushed your change to GitHub as explained above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "# Put the command for cloning your repository here!\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Generate a network graph from data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will look at characters in the book series \"A Song of Ice and Fire\" (\"A Game of Thrones\") by George R. R. Martin, specifically the book \"A Storm of Swords\". The series features a large number of characters in a variety of places around a fantasy world. Some of them appear with each other, while others never meet. We will model these character coappearances as an undirected graph. Every node will be a character and there will be a edge between two characters if they co-appeared (defined as: \"their names appear within 15 words of each other in the text\").\n",
    "\n",
    "You can find the relevant data file here: https://raw.githubusercontent.com/msu-cmse-courses/cmse202-S22-data/main/data/stormofswords.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.1 (3 points)**: To get started, **download the `.csv` file and place it in the same directory as your notebook**, then **read in the `stormofswords.csv` dataset** and finally **display the first few rows of the data**. You can use **Pandas** for this task or any other Python tool you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "characters = pd.read_csv('stormofswords.csv')\n",
    "\n",
    "print(characters.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see three columns: `Source`, `Target`, and `Weight`. We are going to ignore `Weight` in this exam (it is the number of times two characters co-appear). `Source` and `Target` are the two (unique) character names that co-appear. We will now create a `networkx` graph using this dataset.\n",
    "\n",
    "&#9989; **Question 2.2 (4 points)**: **Create an undirected `networkx` graph** (you can call it `G`). Make sure it is a undirected graph. Then, iterate over the dataset and **add edges between the `Source` and `Target` characters** on each line. Ignore the weights. (The resulting graph should now have an edge per entry in the dataset and the set of all names should be the set of all nodes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "# Importing modules\n",
    "import networkx as nx\n",
    "\n",
    "# Creating an empty graph object (undirected, so no DiGraph!)\n",
    "G = nx.Graph()\n",
    "\n",
    "# populate the graph, IGNORE weights\n",
    "for _, edge in characters.iterrows():\n",
    "    G.add_edge(edge['Source'], edge['Target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now visualize the graph.\n",
    "\n",
    "&#9989; **Question 2.3 (5 points)**: Create a large figure for drawing the graph using something like `plt.figure(figsize=(20,20))`. Then, draw the graph using `networkx`. Make sure the nodes in the graph visualization are labeled. Also, choose two colors of your liking. Make sure that when drawing your graph, the `\"Daenerys\"` node has one color and all other nodes have a different color. (Partial credit if labels are missing and/or colors are not set as described.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "colors = []\n",
    "for n in G:\n",
    "    if n == 'Daenerys':\n",
    "        colors.append('r')\n",
    "    else:\n",
    "        colors.append('y')\n",
    "\n",
    "nx.draw(G, node_color=colors, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **only the graph you created (not the initial row-based data)**, answer the following questions:\n",
    "\n",
    "&#9989; **Question 2.4 (1 point)** What is the number of characters appearing in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.5 (1 point)** With how many characters does `\"Cersei\"` co-appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "G.degree(\"Cersei\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.6 (1 point)** True or False?: `\"Drogo\"` co-appears with `\"Tyrion\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "G.has_edge(\"Drogo\",\"Tyrion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.7 (1 point)** Using the relevant `networkx` function (consult the documentation/internet resources), **find the \"shortest path\" between `\"Qyburn\"` and `\"Illyrio\"`**. The two characters do not appear together, but you should provide a set of nodes to \"traverse\" to get from one character to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "nx.shortest_path(G, 'Qyburn', 'Illyrio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "m\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 2**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Perform a regression analysis on data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be looking at a dataset of various types of fish sold on a fish market. You can find the dataset to download here: https://raw.githubusercontent.com/msu-cmse-courses/cmse202-S22-data/main/data/Fish.csv\n",
    "\n",
    "&#9989; **Question 3.1 (2 points)**: To get started, **download the `.csv` file and place it in the same directory as your notebook**, then **read in the `Fish.csv` dataset** and finally **display the first few rows of the data**. You can use **Pandas** for this task or any other Python tool you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Fish.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a list of fish with one column containing the `Species` and then several measurements, such as `Weight`, various `Length`s, `Height` and `Width`. We will be trying to predict `Weights` using linear regression using the other measurements (`Length1`, `Length2`, `Length3`, and `Height`).\n",
    "\n",
    "&#9989; **Question 3.2 (3 points)**: Create two arrays and/or dataframes from the data you just loaded, one of them called `labels`, the other one called `features`. `labels` should **only** include the `Weights` column, while `features` should include all columns **except for** `Weights` and `Species`. We will NOT be using the `Species` column for this part of the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "labels = df[['Weight']]\n",
    "features = df[['Length1', 'Length2', 'Length3', 'Height', 'Width']]\n",
    "\n",
    "print(labels.head())\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the labels and features to fit, we will use the `statsmodels` `OLS` model to fit it. \n",
    "\n",
    "&#9989; **Question 3.3 (2 point)**: Before we do this, **add a column of constants 1.0 to the `features`**. There is a `statsmodel` function you saw in class that allows you to do that. Call this new data structure `features_const`. (If you cannot figure this out, you can use `features` instead of `features_const` for the next questions.) Print `features_const` to make sure the new column exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import statsmodels.api as sm \n",
    "\n",
    "features_const = sm.add_constant(features)\n",
    "\n",
    "print(features_const.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will perform the actual fit.\n",
    "\n",
    "&#9989; **Question 3.4 (3 points)**: Using `statsmodels` `OLS`, perform a fit using `labels` (containing `Weight`) as the quantity to fit (y) and fit it to the `features` (x). Once the fit is done print the fit `summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "lm = sm.OLS(labels,features_const).fit() # fitting the model\n",
    "print(lm.summary()) # model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.5 (2 points)**: Which feature would you say contributes the least to the fit result and/or is the least important? Make sure to justify your answer with a sentence or two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do This - Erase the contents of this cell an put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "Something on the lines of \"`Length2` has a very high p-value\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.6 (2 points)**: Now **run the fit again, but with the \"least important\" feature you identified in Q3.5 removed**. Make sure your new features still include the `constant` column (unless that happens to be the least important feature). **Print the fit `summary()`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "labels = df[['Weight']]\n",
    "features = df[['Length1', 'Length3', 'Height']]\n",
    "\n",
    "features_const = sm.add_constant(features)\n",
    "\n",
    "lm = sm.OLS(labels,features_const).fit() # fitting the model\n",
    "print(lm.summary()) # model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.7 (2 points)**: Comment on the difference in fit quality between the two fits you just performed. Is one much better or worse than the other? Is the difference what you expected? Explain how you judged the quality given the fit statistics you printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do This - Erase the contents of this cell an put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "Something along the lines of \"They both have pretty much the same R-squared, so removing `Length2` did not make much of a difference. The quantity used was R-squared. This was expected because of the high p-value / low importance of the feature we removed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 3**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Perform a support vector machine (SVM) classification on data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the same `Fish.csv` dataset as in Part 3 here. If you have not done part 3 (yet), make sure you download it and place it next to your notebook (see part 3 for the URL).\n",
    "\n",
    "&#9989; **Question 4.1 (1 point)**: **Load the `Fish.csv` dataset again (just to make sure you have a fresh copy loaded).** Display the first few lines of the loaded dataset (you should already have this from Part 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "df = pd.read_csv('Fish.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be looking at classification. This time, we will keep the `Species` column and try to see if we can classify the species using the measurements that are given. We will also perform a train-test split on the data first.\n",
    "\n",
    "&#9989; **Question 4.2 (3 points)**: **Create two data structures** (e.g. dataframes) from your table: one called `labels` containing only `Species` and one called `features` containing all other columns (`Weight`, `Length1`, `Length2`, `Length3`, `Height`, and `Width`). Then perform a **train-test-split** using functions we used in class. Use a `train_size` of `0.75` and `random_state` of `42`. You should now have a training and a testing set with \"labels\" and \"features\" each.\n",
    "\n",
    "**Note:** if you are using Pandas dataframes, you will need to make sure to use `['Species']` for the single-column selection, not `[['Species']]` as the latter will create a list of single-entry lists that the classification code we are going to use later will not like. However, for the feature selection, you will need to use a python list as an index and thus need double brackets (`[[]]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = df['Species']  ## the SVM code later will NOT like `df[['Species']]`!\n",
    "features = df[['Length1', 'Length2', 'Length3', 'Height', 'Weight', 'Width']]\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.3 (6 points)**: **Fit an SVM classifier (using the `sklearn` `SVC` class) to the dataset.** Use a `linear` kernel and set the hyper-parameter `C=1.` Then **fit your training set** and use the resulting fit to **predict your the testing set** so you get predicted labels for the testing set. Finally, print the fit statistics using `confusion_matrix` and `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='linear', C=1.)\n",
    "svc.fit(features_train, labels_train)\n",
    "\n",
    "labels_predict = svc.predict(features_test)\n",
    "\n",
    "print(confusion_matrix(labels_test,labels_predict))\n",
    "print(classification_report(labels_test,labels_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.4 (3 points)**: Interpret the output of your classification report and the confusion matrix by answering these three questions (provide at least 1 or 2 sentences each for full credit): \n",
    "* Explain in a few sentences what you observe in the confusion matrix. \n",
    "* Would you consider this a good or a bad classifier?\n",
    "* Which quantity from the classification report did you use to make this judgement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do This - Erase the contents of this cell an put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "* mostly on the diagonal\n",
    "* Looks to be a good classifier\n",
    "* Accuracy seems high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.5 (3 points)**: We have been using machine learning \"jargon\" in this section and in class. In a few sentences each explain the following concepts:\n",
    "* What are \"labels\" and \"features\"?\n",
    "* Why do we need \"training sets\" and \"testing sets\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do This - Erase the contents of this cell an put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 4**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Final!\n",
    "\n",
    "Make sure all of your changes to your repository are committed and pushed to GitHub. Also upload a copy of this notebook to the dropbox on D2L in case something went wrong with your repository or if you couldn't get the repository to work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
