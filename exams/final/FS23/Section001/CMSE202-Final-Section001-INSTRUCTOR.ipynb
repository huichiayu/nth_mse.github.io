{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER (for making sure this gets removed)\n",
    "\n",
    "# Grading Rubric (50 points total)\n",
    "\n",
    "## Part 1 (2 points)\n",
    "\n",
    "* **Question 1.1** (2 points):\n",
    "  * 1 point for creating the GitHub repository directory\n",
    "  * 1 point for correctly writing the cloning command\n",
    "\n",
    "## Part 2 (16 points)\n",
    "\n",
    "* **Question 2.1** (3 points):\n",
    "  * 1 point for downloading the data\n",
    "  * 1 point for reading the .csv file\n",
    "  * 1 point for displaying the first few lines\n",
    "* **Question 2.2** (4 points):\n",
    "  * 1 point for creating an undirected graph (`nx.Graph()`)\n",
    "  * 1 point for iterating over the dataset\n",
    "  * 1 point for adding edges for every line in the .csv file between `Source` and `Target`\n",
    "  * 1 point for those edges having no weights\n",
    "* **Question 2.3** (5 points):\n",
    "  * 1 point for making a large figure (bigger than the matplotlib default)\n",
    "  * 2 points for drawing the graph\n",
    "  * 1 point for setting the color of the most-connected node\n",
    "  * 1 point for setting the color of the least-connected nodes\n",
    "* **Question 2.4** (1 point):\n",
    "  * 1 point for finding the right function\n",
    "* **Question 2.5** (1 point):\n",
    "  * 1 point for finding the right function\n",
    "* **Question 2.6** (1 point):\n",
    "  * 1 point for finding the right function\n",
    "* **Question 2.7** (1 point):\n",
    "  * 1 point for finding the right function\n",
    "\n",
    "## Part 3 (16 points)\n",
    "\n",
    "* **Question 3.1** (2 points):\n",
    "  * 1 point for downloading the data\n",
    "  * 1 point for reading the .csv file\n",
    "* **Question 3.2** (3 points):\n",
    "  * 1 point for selecting the `labels` data (the `selling_price` column only)\n",
    "  * 1 point for selecting the `features` data (all of the other columns)\n",
    "  * 1 point for printing the first few lines of both of them\n",
    "* **Question 3.3** (2 points):\n",
    "  * 1 point for adding the column\n",
    "  * 1 point for printing `features_const`\n",
    "* **Question 3.4** (3 points):\n",
    "  * 2 points for performing the fit\n",
    "  * 1 point for printing the summary\n",
    "* **Question 3.5** (2 points):\n",
    "  * 2 points for an explanation\n",
    "* **Question 3.6** (2 points):\n",
    "  * 1 point for selecting the new features\n",
    "  * 1 point for running the fit again\n",
    "* **Question 3.7** (2 points):\n",
    "  * 1 point for explaining which fit summary parameter was used\n",
    "  * 1 point for pointing out that the fit quality doesn't change much\n",
    "\n",
    "## Part 4 (16 points)\n",
    "\n",
    "* **Question 4.1** (1 points):\n",
    "  * 1 point for loading the dataset and displaying the first few lines\n",
    "* **Question 4.2** (3 points):\n",
    "  * 1 point for creating the correct `labels` and `features\n",
    "  * 1 point for creating the train-test split\n",
    "  * 1 point for using the correct `train_size` and `random_state`\n",
    "* **Question 4.3** (6 points):\n",
    "  * 1 point for fitting the SVC\n",
    "  * 1 point for using a linear kernel and C=0.1\n",
    "  * 1 point for using the training set for fitting (not the full set or the testing set)\n",
    "  * 1 point for predicting\n",
    "  * 1 point for predicting on the testing set (not the training set or full set)\n",
    "  * 1 point for printing both the `confusion_matrix` and the `classification_report`\n",
    "* **Question 4.4** (3 points):\n",
    "  * 1 point for \"confusion matrix is mostly diagonal, only a few off-diagonal elements\"\n",
    "  * 1 point for \"looks to be a good classifier\"\n",
    "  * 1 point for the quantity used to judge the classifier (e.g. accuracy)\n",
    "* **Question 4.5** (3 points):\n",
    "  * 1 point for explaining labels and features\n",
    "  * 2 points for explaining why we need training and testing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: right;\"> &#9989; Put your name here</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Final (Section 001 - Fall 2023)\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed having now finished CMSE 202. In particular, you'll be committing and pushing repository changes to a GitHub repository, working with data to build a network graph, performing regression analysis, and classifying data using a machine learning classifier. You should find that you have all of the skills necessary to complete this exam having completed the second half of CMSE 202!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. Once you've read through it, you'll probably want to make sure you do Part 1 first to ensure that your GitHub repository is working correctly. Let your instructor know right away if you run into issues!\n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. **However**: The use of any person-to-person communication software is absolutely not acceptable. If you are seen accessing your email, using a chat program (e.g. Slack), or any sort of collaborative cloud storage or document software (e.g. Google Documents), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**You can also use _your version_ of past CMSE 202 assignments and the CMSE 202 course materials as a resource!**\n",
    "\n",
    "You can also use any publicly available generative AI tool, if you find such a tool to be useful, **but you must properly cite the tool in your exam submission if you do so**.\n",
    "\n",
    "**Keep your eyes on your screen!** Unfortunately, there isn't enough space in the room for everyone to sit at their own table so please do your best to keep your eyes on your own screen. This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero. If you're completing the exam virtually, the same standards of academic integrity apply!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 0: Academic integrity statement\n",
    "\n",
    "Read the following statement and edit the markdown text to put your name in the statement. This is your commitment to doing your own authentic work on this exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I, **INSERT NAME HERE**, affirm that this exam represents my own authetic work, without the use of any unpermitted aids or resources or person-to-person communication. I understand that this exam an an opportunity to showcase my own progress in developing and improving my computational skills and have done my best to demonstrate those skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Add to your Git repository to track your progress on your exam (2 points)\n",
    "\n",
    "Before you get to far along in the exam, you're going to add it to the `cmse202-f23-turnin` repository you created in class so that you can track your progress on the exam and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "1. Navigate to your `cmse202-f23-turnin` repository and create a new directory called `final`.\n",
    "2. Move this notebook into that **new directory** in your repository, then **add it and commit it to your repository**.\n",
    "1. Finally, to test that everything is working, \"git push\" the file so that it ends up in your GitHub repository.\n",
    "\n",
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" respository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the noteobok, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-f23-turnin`\" repository inside the `final` directory that you just created.  Periodically, **you'll be asked to commit your changes to the repository and push them to the remote GitHub location**. Of course, you can always commit your changes more often than that, if you wish.  It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the project for a bit.\n",
    "\n",
    "&#9989; **Question 1.1 (2 points)**: **Do this**: Before you move on, put the command that your instructor should run to clone your repository in the markdown cell below. Also make sure that you created the directory and pushed your change to GitHub as explained above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "# Put the command for cloning your repository here!\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Generate a network graph from data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will look at characters in the Marvel comic book universe. The Marvel universe features a large number of characters that have appeared in a large number of comics over the years. Some of them appear with each other, while others never meet. We will model these character co-appearances as an undirected graph. Every node will be a character and there will be a edge between two characters if they co-appeared in a comic book. The dataset originally comes from [here](https://github.com/melaniewalsh/sample-social-network-datasets/tree/master/sample-datasets/marvel).\n",
    "\n",
    "You can find a copy of the relevant data file here:\n",
    "\n",
    "`https://raw.githubusercontent.com/msu-cmse-courses/cmse202-supplemental-data/main/data/marvel-unimodal-edges.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.1 (3 points)**: To get started, **download the `.csv` file and place it in the same directory as your notebook**, then **read in the `marvel-unimodal-edges.csv` dataset** and finally **display the first few rows of the data**. You can use **Pandas** for this task or any other Python tool you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "characters = pd.read_csv('marvel-unimodal-edges.csv')\n",
    "\n",
    "characters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see three columns: `Source`, `Target`, and `Weight`. We are going to ignore `Weight` in this exam (it is the number of times two characters co-appear in the comics). `Source` and `Target` are the two (unique) character names that co-appear. We will now create a `networkx` graph using this dataset.\n",
    "\n",
    "&#9989; **Question 2.2 (4 points)**: **Create an undirected `networkx` graph** (you can call it `G`). Make sure it is a undirected graph. Then, iterate over the dataset and **add edges between the `source` and `target` characters** on each line. Ignore the weights. (The resulting graph should now have an edge per entry in the dataset and the set of all names should be the set of all nodes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "# Importing modules\n",
    "import networkx as nx\n",
    "\n",
    "# Creating an empty graph object (undirected, so no DiGraph!)\n",
    "G = nx.Graph()\n",
    "\n",
    "# populate the graph, IGNORE weights\n",
    "for _, edge in characters.iterrows():\n",
    "    G.add_edge(edge['Source'], edge['Target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now visualize the graph.\n",
    "\n",
    "&#9989; **Question 2.3 (5 points)**: Create a large figure for drawing the graph using something like `plt.figure(figsize=(20,20))`. Then, draw the graph using `networkx`. Make sure that when drawing your graph, you accomplish the following:\n",
    "1. The `\"Captain America\"` node should have a unique node color, he's the most connected character,\n",
    "2. The characters `\"Asp Ii / Cleo\"` and `\"Black Mamba / Tanya Se\"` should have the same color as each other, but it should be _different_ color from that of Captain America.\n",
    "3. All of the other characters should have a third, different color.\n",
    "\n",
    "To recap, you should have **three** different colors in your graph, one for Captain America, one for Asp and Black Mamba, and one for all of the other characters.\n",
    "\n",
    "(Partial credit if you generate the graph but the colors are not set as described.)\n",
    "\n",
    "**Note**: this will be a very crowded graph because it's a complex, heavily-interconnected network, but you should see that Captain America is somewhere in the middle of the graph and that Asp and Black Mamba are connected to each other and on the outskirts of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "colors = []\n",
    "for n in G:\n",
    "    if n == 'Captain America':\n",
    "        colors.append('r')\n",
    "    elif n in ['Asp Ii / Cleo','Black Mamba / Tanya Se']:\n",
    "        colors.append('b')\n",
    "    else:\n",
    "        colors.append('gray')\n",
    "\n",
    "#nx.draw(G, node_color=colors, with_labels=True, font_size=10, font_weight='bold')\n",
    "nx.draw(G, node_color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER for figuring out most connected characters\n",
    "sorted(G.degree, key=lambda x: x[1], reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER for figuring out least connected characters\n",
    "sorted(G.degree, key=lambda x: x[1], reverse=False)[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using **only the graph you created (not the initial row-based data)**, answer the following questions.\n",
    "\n",
    "You may find it useful to review the \"Methods\" section of the [networkx Graph documentation](https://networkx.org/documentation/stable/reference/classes/graph.html#methods).\n",
    "\n",
    "&#9989; **Question 2.4 (1 point)** What is the number of characters appearing in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.5 (1 point)** With how many characters does `\"Vision\"` co-appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "G.degree(\"Vision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.6 (1 point)** True or False?: `\"Hyperion\"` co-appears with `\"Hammerhead\"`. Use a graph method to determine this. If you want to verify that you're right, you could create a new visualization of your graph and give these two characters unique colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "G.has_edge(\"Hyperion\",\"Hammerhead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "colors = []\n",
    "for n in G:\n",
    "    if n == 'Hyperion':\n",
    "        colors.append('g')\n",
    "    elif n == 'Hammerhead':\n",
    "        colors.append('m')\n",
    "    else:\n",
    "        colors.append('gray')\n",
    "\n",
    "#nx.draw(G, node_color=colors, with_labels=True, font_size=10, font_weight='bold')\n",
    "nx.draw(G, node_color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.7 (1 point)** Using the relevant `networkx` function (consult the documentation/internet resources), **find the \"shortest path\" between `\"Sif\"` and `\"Callisto\"`**. The two characters do not appear together, but you should be able to determine a set of nodes to \"traverse\" to get from one character to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "nx.shortest_path(G, \"Sif\", \"Callisto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 2**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Perform a regression analysis on data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be looking at a dataset of diamonds of varying properties and qualities and their prices. You can find the dataset to download here:\n",
    "\n",
    "`https://raw.githubusercontent.com/msu-cmse-courses/cmse202-supplemental-data/main/data/diamonds.csv`\n",
    "\n",
    "&#9989; **Question 3.1 (2 points)**: To get started, **download the `diamonds.csv` file and place it in the same directory as your notebook**, then **read in the `diamonds.csv` dataset** and finally **display the first few rows of the data**. You can use **Pandas** for this task or any other Python tool you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('diamonds.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a list of diamonds with several different pieces of information about them, such as the number of carats, the cut, color, clarity, and so on...\n",
    "\n",
    "You will be trying to predict `price` using linear regression using a subset of the other diamond features.\n",
    "\n",
    "&#9989; **Question 3.2 (3 points)**: Create two arrays and/or dataframes from the data you just loaded, one of them called `labels`, the other one called `features`. `labels` should **only** include the `price` column, while `features` should include **just the following columns**:\n",
    "* `carat`\n",
    "* `depth`\n",
    "* `table`\n",
    "* `x`\n",
    "* `y`\n",
    "* `z`\n",
    "\n",
    "You should be able to create a new dataframe with only these columns or drop all the columns that should *not* be in your `features` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "labels = df['price']\n",
    "features = df[['carat','depth','table','x','y','z']]\n",
    "\n",
    "print(labels.head())\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the labels and features to fit, we will use the `statsmodels` `OLS` model to fit it. \n",
    "\n",
    "&#9989; **Question 3.3 (2 point)**: Before we do this, **add a column of constants (set to 1.0) to the `features`**. There is a `statsmodel` function you saw in class that allows you to do that. Call this new data structure `features_const`. (If you cannot figure this out, you can use `features` instead of `features_const` for the next questions.) Print/display `features_const` to make sure the new column exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import statsmodels.api as sm \n",
    "\n",
    "features_const = sm.add_constant(features)\n",
    "#features_const = features.copy()\n",
    "\n",
    "features_const.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will perform the actual fit.\n",
    "\n",
    "&#9989; **Question 3.4 (3 points)**: Using `statsmodels` `OLS`, perform a fit using `labels` (containing `price`) as the quantity to fit (y) and fit it to the `features_const` (X). Once the fit is done print the fit `summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "lm = sm.OLS(labels,features_const).fit() # fitting the model\n",
    "lm.summary() # model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.5 (2 points)**: Which feature would you say contributes the least to the fit result and/or is the least important? Make sure to justify your answer with a sentence or two. If you were unable to successfully add the constant term and the results do not indicate a least important feature, explain why that might be. Then for Question 3.6, just choose a feature to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do This - Erase the contents of this cell an put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "Something on the lines of \"`z` has the highest p-value\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.6 (2 points)**: Now **run the fit again, but with the \"least important\" feature you identified in Q3.5 removed**. Make sure your new features still include the `constant` column (unless that happens to be the least important feature). **Print the fit `summary()`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "labels = df['price']\n",
    "features = df[['carat','depth','table','x','y']]\n",
    "\n",
    "features_const = sm.add_constant(features)\n",
    "\n",
    "lm = sm.OLS(labels,features_const).fit() # fitting the model\n",
    "lm.summary() # model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.7 (2 points)**: Comment on the difference in fit quality between the two fits you just performed. Is one much better or worse than the other? Is the difference what you expected? Explain how you judged the quality given the fit statistics you printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do This - Erase the contents of this cell an put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "Something along the lines of \"They both have pretty much the same R-squared, so removing `z` did not make much of a difference. The quantity used was R-squared. This was expected because of the high p-value / low importance of the feature we removed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 3**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Perform a support vector machine (SVM) classification on data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the exam, you will be using a dataset that is based on some precise measurements of a variety of dry beans to try and classify beans by their type. You can download the dataset from here:\n",
    "\n",
    "`https://raw.githubusercontent.com/msu-cmse-courses/cmse202-supplemental-data/main/data/Dry_Bean_Dataset.csv`\n",
    "\n",
    "&#9989; **Question 4.1 (1 point)**: **Load the `Dry_Bean_Dataset.csv`.** Display the first few lines of the loaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Dry_Bean_Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to perform **classification**. We will try to see if we can classify the bean type using the properties that are given. We will need perform a train-test split on the data first.\n",
    "\n",
    "&#9989; **Question 4.2 (3 points)**: **Create two data structures** (e.g. dataframes) from your table: one called `labels` containing **only** the values from the `Class` column and one called `features` containing **everything but** the `Class` column.\n",
    "\n",
    "Then, perform a **train-test-split** using functions we used in class. Use a `train_size` of `0.75` and `random_state` of `42`. You should now have a training and a testing set with \"labels\" and \"features\" each.\n",
    "\n",
    "**Syntax Note:** if you are using Pandas dataframes for creating and storing your `labels` variable, you will need to make sure to use `['Class']` for the single-column selection, not `[['Class']]` as the latter will create a list of single-entry lists that the classification code you are going to use later will not like! If you run into and issue and you think it might be related to this, notify your instructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = df['Class']  ## the SVM code later will NOT like `df[['Class']]` if a student does it that way!\n",
    "features = df.drop(['Class'], axis=1)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.3 (6 points)**: **Fit an SVM classifier (using the `sklearn` `SVC` class) to the dataset.** Use a `linear` kernel and set the hyper-parameter `C=1.0`. Then **fit your *training* set** and use the resulting fit to **predict your the *testing* set** so you get predicted labels for the testing set. Finally, print the fit statistics using `confusion_matrix` and `classification_report` (if you prefer the visual plot version of the confusion matrix, you can use `ConfusionMatrixDisplay` from `sklearn.metrics` instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='linear', C=1.0)\n",
    "svc.fit(features_train, labels_train)\n",
    "\n",
    "labels_predict = svc.predict(features_test)\n",
    "\n",
    "print(confusion_matrix(labels_test,labels_predict))\n",
    "print(classification_report(labels_test,labels_predict))\n",
    "ConfusionMatrixDisplay.from_estimator(svc, features_test, labels_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.4 (3 points)**: Interpret the output of your classification report and the confusion matrix by answering these three questions (provide at least 1 or 2 sentences each for full credit): \n",
    "* Explain in a few sentences what you observe in the confusion matrix. \n",
    "* Would you consider this a good or a bad classifier?\n",
    "* Which quantity from the classification report did you use to make this judgement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do This - Erase the contents of this cell an put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "* mostly on the diagonal\n",
    "* Looks to be a good classifier\n",
    "* Accuracy seems high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.5 (3 points)**: We have been using machine learning \"jargon\" in this section and in class. In a few sentences each explain the following concepts:\n",
    "* What are \"labels\" and \"features\"?\n",
    "* Why do we need \"training sets\" and \"testing sets\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do This - Erase the contents of this cell an put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "* Labels are the values we are trying to predict, features are the values we are using to predict them.\n",
    "* We need training sets to train the model, and testing sets to test the model. If we used the same data for both, we would not be able to tell if the model was overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 4**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Final!\n",
    "\n",
    "Make sure all of your changes to your repository are committed and pushed to GitHub. Also upload a copy of this notebook to the dropbox on D2L in case something went wrong with your repository or if you couldn't get the repository to work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
