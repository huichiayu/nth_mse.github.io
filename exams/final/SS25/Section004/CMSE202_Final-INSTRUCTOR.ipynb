{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exam (Individual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Put your name here.</p>\n",
    "### <p style=\"text-align: right;\"> &#9989; Put your _GitHub username_ here.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Final (Section 004 - Spring 25)\n",
    "\n",
    "\n",
    "# &#128721; READ EVERYTHING CAREFULLY\n",
    "\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed thus far this semester. In particular, you'll practice setting up a GitHub repository, committing and pushing repository changes, downloading data with command line tools, performing some data analysis, possibly using a new Python package, and writing a python class. You should find that you have all of the skills necessary to complete this exam with even just eight weeks of CMSE 202 under your belt!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. Once you've read through it, try doing Parts 1 and 2 first so that you have your repository set up and you download all necessary data files as they will be necessary to complete the assigned tasks. Let your instructor know right away if you have problems downloading the data!\n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. **However**: The use of any person-to-person communication software is absolutely not acceptable. If you are seen accessing your email, using a chat program (e.g. Slack), or any sort of collaborative cloud storage or document software (e.g. Google Documents), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**Important Guidelines on AI Tool Usage**\n",
    "\n",
    "This exam allows the use of AI tools (such as ChatGPT, Claude, HiTA) with specific guidelines that mirror real-world professional practices. These tools should enhance your learning and problem-solving process, not replace your intellectual engagement. Here are the key requirements:\n",
    "\n",
    "1. **Appropriate Use of AI**:\n",
    "   - Use AI as a learning assistant to understand concepts, debug code, or get unstuck\n",
    "   - Use AI to improve your solution approach or verify your thinking\n",
    "   - Use AI to learn about new Python packages or functions you might need\n",
    "\n",
    "2. **Prohibited Uses**:\n",
    "   - Direct copying of AI-generated solutions without understanding\n",
    "   - Asking AI to complete entire questions without your intellectual input\n",
    "   - Using AI to modify provided starter code or test cases\n",
    "   - Using AI to circumvent learning objectives or problem requirements\n",
    "\n",
    "3. **Documentation Requirements**:\n",
    "   - You must cite any AI assistance received by adding a comment that includes:\n",
    "     * The AI tool used\n",
    "     * The specific question you asked\n",
    "     * How you modified or improved upon the AI's suggestion\n",
    "   - Example: \"# AI assistance: Used Claude to understand lmfit parameter initialization. Modified the suggested approach to include custom bounds.\"\n",
    "\n",
    "4. **Evaluation Implications**:\n",
    "   - Questions showing signs of direct AI solution copying will receive zero points\n",
    "   - Evidence of not following problem instructions, even if AI-suggested, will result in zero points\n",
    "   - Modified starter code or test cases will result in zero points for that question\n",
    "\n",
    "Remember: The goal is to demonstrate your understanding and problem-solving abilities. AI tools should support your learning, not replace your critical thinking and coding skills.\n",
    "\n",
    "**Note**: Traditional open internet resources (documentation, Stack Overflow, etc.) remain available, but person-to-person communication tools are not permitted.\"\n",
    "\n",
    "**Keep your eyes on your screen!** Unfortunately, there isn't enough space in the room for everyone to sit at their own table so please do your best to keep your eyes on your own screen. This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Moira](https://media.giphy.com/media/26gs78HRO8sOuhTkQ/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "Navigate through the midterm using these links:\n",
    "\n",
    "\n",
    "* [Part 0: Upgrade packages](#part0) (1 point)\n",
    "* [Part 1: Git](#part1) (9 points)\n",
    "* [Part 2: Data Preprocessing](#part2) (27 points)\n",
    "* [Part 3: Logistic Regression](#part3) (19 points)\n",
    "* [Part 4: Support Vector Machines](#part4) (14 points)\n",
    "* [Part 5: Comparison and Conclusion](#part5) (8 points)\n",
    "* [Part 6: Conceptual Questions](#part6) (10 points)\n",
    "* [Part 7: Conclusion](#conclusion) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:50:14.352819Z",
     "start_time": "2022-12-07T03:50:14.350105Z"
    }
   },
   "outputs": [],
   "source": [
    "grades = [1, 9, 27, 19, 14, 8, 10, 5]\n",
    "\n",
    "print(f\"The total grade for this final is {sum(grades)}\" )\n",
    "# Should print 93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"part0\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 0: Upgrade Packages\n",
    "\n",
    "**&#9989; Question 0.1 (1 point)**: Run the cell below. Do you have the correct packages ? If not upgrade them. **You must do this in order to avoid issues in the rest of the notebook.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:15:16.292936Z",
     "start_time": "2022-12-07T03:15:16.283043Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm \n",
    "\n",
    "from sklearn import __version__ as sk_version\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "print(f\"Sklearn version should be 1.6.0 and I have {sk_version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id=\"part1\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## Part 1: Git (9 points)\n",
    "\n",
    "For this assignment, you're going to add it to the `cmse202-s25-turnin` repository you created in class so that you can track your progress on the assignment and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Question 1.1 (1 point)**: Navigate to your `cmse202-s25-turnin` **local** repository and create a new directory called `final` and copy this notebook in that new directory.\n",
    "\n",
    "``` bash\n",
    "# Put the command(s) for creating the new directory\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.2 (3 points)** Check the status of your local `git`.\n",
    "\n",
    "``` bash \n",
    "# Put the command you used to check the status of git\n",
    "\n",
    "```\n",
    "Copy and paste below the output of the command.\n",
    "\n",
    "``` bash\n",
    "# Paste it here\n",
    "```\n",
    "\n",
    "What is the name of the branch you are in ? \n",
    "\n",
    "``` bash\n",
    "# Put your answer here\n",
    "```\n",
    "\n",
    "**Important:** You should be in the `main` branch. If you are not switch to the `main` branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.3 (3 points):**\n",
    "Add your name and GitHub username to the top of the notebook, then add and commit **ONLY** the notebook.\n",
    "\n",
    "``` bash\n",
    "# Put the command(s) to add and commit here \n",
    "```\n",
    "\n",
    "What is the commit message you used ?\n",
    "\n",
    "``` bash\n",
    "# Answer the question here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.4 (1 point):** Before moving on. Check that the notebook you are working on is the correct one. Run the following cell. **Are you in the new folder you just created?** If not close this notebook and open the one in the `final` folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T20:23:32.165597Z",
     "start_time": "2022-12-05T20:23:31.986031Z"
    }
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.5 (1 point):** Finally push the updated notebook to GitHub.\n",
    "\n",
    "``` bash\n",
    "# Put the command you used to push to GitHub here.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" repository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the notebook, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-s25-turnin`\" repository inside the `final` directory that you just created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "---\n",
    "<a id=\"part2\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Auto MPG Dataset Analysis Assignment\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this assignment, you will analyze the Auto MPG dataset, which contains information about various car models. You'll create a binary classification task, comparing logistic regression and Support Vector Machine (SVM) models to predict whether a car has above-median fuel efficiency.\n",
    "\n",
    "The Auto MPG dataset contains data about automobile models from the late 1970s and early 1980s, including characteristics such as horsepower, weight, acceleration, and their fuel efficiency measured in miles per gallon (MPG).\n",
    "\n",
    "For this assignment, you will:\n",
    "1. Load and explore the dataset\n",
    "2. Create a binary target variable based on MPG values\n",
    "3. Build classification models using logistic regression and SVM\n",
    "4. Compare model performance using appropriate metrics\n",
    "\n",
    "\n",
    "## Part 2: Data Loading and Exploratory Data Analysis (27 points)\n",
    "\n",
    "**&#9989; (6 points) Task 2.1:** You can get the dataset at this link `https://archive.ics.uci.edu/dataset/9/auto+mpg`\n",
    "\n",
    "* Load the Auto MPG dataset using pandas. (3 points)\n",
    "* Make sure the put names on the columns of the dataframe (2 points)\n",
    "* Display the first 10 rows (1 point)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T20:23:35.697903Z",
     "start_time": "2022-12-05T20:23:35.694510Z"
    }
   },
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "# \n",
    "# The following uses code similar to what we have used in class Day 14\n",
    "# Load the Auto MPG dataset with appropriate column names\n",
    "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', \n",
    "                'acceleration', 'model_year', 'origin', 'car_name']\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "\n",
    "# The dataset is fixed-width formatted, so we use read_fwf\n",
    "data = pd.read_fwf(url, names=column_names)\n",
    "\n",
    "# Students who struggle with loading the dataset should be directed to use the code in the website.\n",
    "# from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# # fetch dataset \n",
    "# auto_mpg = fetch_ucirepo(id=9) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "# X = auto_mpg.data.features \n",
    "# y = auto_mpg.data.targets \n",
    "  \n",
    "# # metadata \n",
    "# print(auto_mpg.metadata) \n",
    "  \n",
    "# # variable information \n",
    "# print(auto_mpg.variables) \n",
    "\n",
    "\n",
    "# Display first few rows to verify loading\n",
    "print(\"First 10 rows of the dataset:\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T20:23:36.383889Z",
     "start_time": "2022-12-05T20:23:36.381940Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "**&#9989; (6 points) Task 2.2:** Perform basic data cleaning. Write code in the next cell to answer the following questions\n",
    "\n",
    "* Are there any missing values or null values? If so what columns and how many? (3 points)\n",
    "* Drop the rows with the missing values. (1 point)\n",
    "* Drop the `car_name` column. (1 point)\n",
    "* Check your work by showing that there are no missing values (1 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "\n",
    "# Check data types and info\n",
    "print(\"\\nDataset information:\")\n",
    "display(data.info())\n",
    "\n",
    "# Check for missing values. This will give None so it won't be useful\n",
    "# print(\"\\nMissing values count:\")\n",
    "# print(data.isnull().sum())\n",
    "\n",
    "# Check for '?' values in the dataset (often representing missing data)\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == object:\n",
    "        if (data[col] == '?').any():\n",
    "            print(f\"Column '{col}' contains '?' values\")\n",
    "\n",
    "# Replace '?' with NaN in the horsepower column and convert to numeric\n",
    "data['horsepower'] = pd.to_numeric(data['horsepower'].replace('?', np.nan))\n",
    "\n",
    "# Check for missing values again\n",
    "print(\"\\nMissing values after replacement:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values\n",
    "data_cleaned = data.dropna()\n",
    "print(f\"\\nOriginal dataset shape: {data.shape}\")\n",
    "print(f\"Cleaned dataset shape: {data_cleaned.shape}\")\n",
    "\n",
    "# Drop the car_name column as it's not needed for modeling\n",
    "data_cleaned = data_cleaned.drop('car_name', axis=1)\n",
    "\n",
    "print(\"\\nCleaned dataset head:\")\n",
    "data_cleaned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (1 point) Task 2.3:** Let's do some EDA. Run the code below and analyze the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical features\n",
    "\n",
    "# Convert 'origin' to categorical\n",
    "data_cleaned['origin'] = data_cleaned['origin'].astype('category')\n",
    "\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(data_cleaned.describe())\n",
    "\n",
    "# Set up the visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Distribution of MPG\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data_cleaned['mpg'], kde=True, bins=20)\n",
    "plt.title('Distribution of Miles Per Gallon (MPG)')\n",
    "plt.xlabel('MPG')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('mpg_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = data_cleaned.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "plt.show()\n",
    "\n",
    "# # Scatter plots of key relationships\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# # MPG vs. Weight\n",
    "# sns.scatterplot(data=data_cleaned, x='weight', y='mpg', ax=axes[0, 0])\n",
    "# axes[0, 0].set_title('MPG vs. Weight')\n",
    "# axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# # MPG vs. Horsepower\n",
    "# sns.scatterplot(data=data_cleaned, x='horsepower', y='mpg', ax=axes[0, 1])\n",
    "# axes[0, 1].set_title('MPG vs. Horsepower')\n",
    "# axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# # MPG vs. Displacement\n",
    "# sns.scatterplot(data=data_cleaned, x='displacement', y='mpg', ax=axes[1, 0])\n",
    "# axes[1, 0].set_title('MPG vs. Displacement')\n",
    "# axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# # MPG vs. Model Year\n",
    "# sns.boxplot(data=data_cleaned, x='model_year', y='mpg', ax=axes[1, 1])\n",
    "# axes[1, 1].set_title('MPG by Model Year')\n",
    "# axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('mpg_relationships.png')\n",
    "# plt.show()\n",
    "\n",
    "# # MPG by origin\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.boxplot(data=data_cleaned, x='origin', y='mpg')\n",
    "# plt.title('MPG by Origin')\n",
    "# plt.xlabel('Origin (1: USA, 2: Europe, 3: Japan)')\n",
    "# plt.ylabel('MPG')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.savefig('mpg_by_origin.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (4 points) Task 2.3:** Answer these questions\n",
    "\n",
    "* Explain the first histogram. What is being plot here? What is frequency? (2 points)\n",
    "* Looking at the correlation matrix plot. What are the features that most strongly correlate with `mpg`? (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (4 points) Task 2.4:** Create a new binary target variable:\n",
    "\n",
    "* Calculate and print the median MPG value (1 point)\n",
    "* Create a new column called 'high_mpg' that equals 1 if a car's MPG is above the median, and 0 otherwise (2 points)\n",
    "* Verify the class distribution of your new target variable. In other words how many cars are above and how many are below the median. Is it 50:50? (1 point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "\n",
    "# Calculate the median MPG\n",
    "median_mpg = data_cleaned['mpg'].median()\n",
    "print(f\"\\nMedian MPG: {median_mpg}\")\n",
    "\n",
    "# Create the binary target variable\n",
    "data_cleaned['high_mpg'] = (data_cleaned['mpg'] > median_mpg).astype(int)\n",
    "\n",
    "# Verify class distribution\n",
    "print(\"\\nClass distribution of 'high_mpg':\")\n",
    "print(data_cleaned['high_mpg'].value_counts())\n",
    "print(f\"Class distribution percentage:\\n{data_cleaned['high_mpg'].value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Visualize the class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='high_mpg', data=data_cleaned)\n",
    "plt.title('Class Distribution of High MPG')\n",
    "plt.xlabel('High MPG (1: Above Median, 0: Below or Equal to Median)')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "# plt.savefig('high_mpg_distribution.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989;(2 points) Task 2.5:** Split the data into training (70%) and testing (30%) sets using an appropriate random seed value. Make sure you have the same class distribution of high mpg in the train/test dataset as in the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "# 1 point for splitting the data into train and test sets\n",
    "# 1 point for stratifying the data\n",
    "\n",
    "# Separate features and target\n",
    "X = data_cleaned.drop(['mpg', 'high_mpg'], axis=1)\n",
    "y = data_cleaned['high_mpg']\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Verify class distribution in train and test sets\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "print(\"\\nClass distribution in testing set:\")\n",
    "print(y_test.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989;(2 points) Task 2.6:** Run the following code and answer this question:\n",
    "\n",
    "* Do you think the data is linearly separable? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "# I can't decide if it is linearly separable or not. None of the scatter plots show a clear separation. \n",
    "# It could be that the data is linearly separable in higher dimensions, but I can't picture that. \n",
    "# 2 points for analyizing the plot and making a decision and supporting their decision\n",
    "# 0 points for answering the question without any explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_cleaned.drop('mpg', axis = 1), hue='high_mpg', diag_kind='kde', palette='Set1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 2\", and push the changes to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "---\n",
    "<a id=\"part3\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## Part 3: Logistic Regression Analysis (19 points)\n",
    "\n",
    "**&#9989; Task 3.1:** Preprocess your data appropriately for logistic regression:\n",
    "\n",
    "An important part of the preparing the data for the ML part is scaling and encoding. We have not covered this in class, so I am not asking you to do it. The code below takes care of this run it and make sure you don't get any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code without modifying it, apart from the name of the dataset\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Preprocess data for logistic regression\n",
    "# Handle categorical variables (one-hot encoding for 'origin')\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "origin_encoded = encoder.fit_transform(X_train[['origin']])\n",
    "origin_cols = [f'origin_{i+2}' for i in range(origin_encoded.shape[1])]\n",
    "origin_train_df = pd.DataFrame(origin_encoded, columns=origin_cols, index=X_train.index)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year']\n",
    "X_train_num = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[numerical_cols]),\n",
    "    columns=numerical_cols,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Combine numerical and encoded categorical features\n",
    "X_train_processed = pd.concat([X_train_num, origin_train_df], axis=1)\n",
    "\n",
    "# Process test data\n",
    "origin_encoded_test = encoder.transform(X_test[['origin']])\n",
    "origin_test_df = pd.DataFrame(origin_encoded_test, columns=origin_cols, index=X_test.index)\n",
    "\n",
    "X_test_num = pd.DataFrame(\n",
    "    scaler.transform(X_test[numerical_cols]),\n",
    "    columns=numerical_cols,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "X_test_processed = pd.concat([X_test_num, origin_test_df], axis=1)\n",
    "\n",
    "print(\"\\nProcessed training data shape:\", X_train_processed.shape)\n",
    "print(\"Processed testing data shape:\", X_test_processed.shape)\n",
    "print(\"\\nFirst 5 rows of processed training data:\")\n",
    "display(X_train_processed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989;(7 points) Task 3.2:** Fit a logistic regression model using the `statsmodels` library:\n",
    "\n",
    "* Use the training data to fit the model (2 points)\n",
    "* Print the summary of your model results (1 point)\n",
    "* Interpret the coefficients and statistical significance of features (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "\n",
    "# (1 point for adding a constant term)\n",
    "# (1 point for fitting the logistic regression model)\n",
    "# (1 point for printing the summary of the model)\n",
    "\n",
    "# Add a constant term for the intercept\n",
    "X_train_sm = sm.add_constant(X_train_processed)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logit_model = sm.Logit(y_train, X_train_sm)\n",
    "logit_result = logit_model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(\"\\nLogistic Regression Model Summary:\")\n",
    "print(logit_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Interpret the coefficients of the logistic regression model here. What are the most important features? Why? \n",
    "How does this compare to the correlation matrix from above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "\n",
    "# (4 points) The student uses the p-values to find the most significant features \n",
    "# and realizes that we are not regressing mpg but the categorial variable high_mpg.\n",
    "# (2 points) Gets the right important features but does not explain why or compares with their original guess\n",
    "# (1 point) Attempts to answer but is way off\n",
    "# (0 points) Does not attempt to answer\n",
    "\n",
    "# Some Claude code for fancyness. This is not required for the grade I am leaving it here for you to play with\n",
    "# Interpret coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': logit_result.params.index,\n",
    "    'Coefficient': logit_result.params.values,\n",
    "    'p-value': logit_result.pvalues,\n",
    "    'Odds Ratio': np.exp(logit_result.params)\n",
    "})\n",
    "\n",
    "# Sort by absolute coefficient value\n",
    "coefficients['Abs_Coef'] = abs(coefficients['Coefficient'])\n",
    "coefficients_sorted = coefficients.sort_values('Abs_Coef', ascending=False)\n",
    "\n",
    "print(\"\\nLogistic Regression Coefficients (sorted by absolute value):\")\n",
    "print(coefficients_sorted)\n",
    "\n",
    "# Identify statistically significant features (p < 0.05)\n",
    "significant_features = coefficients[coefficients['p-value'] < 0.05]\n",
    "print(\"\\nStatistically Significant Features (p < 0.05):\")\n",
    "(significant_features[['Feature', 'Coefficient', 'p-value', 'Odds Ratio']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (6 points) Task 3.3:** Evaluate the logistic regression model:\n",
    "\n",
    "* Make predictions on the test set (1 point)\n",
    "* Create a confusion matrix (1 point)\n",
    "* Display the confusion matrix as a heatmap with Blues colormap (2 points)\n",
    "* Calculate and print accuracy, precision, recall (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Add constant to test data for prediction\n",
    "X_test_sm = sm.add_constant(X_test_processed)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_prob = logit_result.predict(X_test_sm)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Low MPG', 'High MPG'],\n",
    "            yticklabels=['Low MPG', 'High MPG'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "# plt.savefig('logistic_confusion_matrix.png')\n",
    "# plt.show()\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nLogistic Regression Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (4 points) Task 3.4:** Given the results above do you think that the data is linearly separable? Explain and compare with your answer from Task 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "\n",
    "# The data is not linearly separable, because if it were we would have a perfect accuracy\n",
    "# (4 points) The student understands that the data is not linearly separable and explains why\n",
    "# (3 points) The student understands that the data is not linearly separable but the explanation is not clear\n",
    "# (2 points) The student understands that the data is not linearly separable but does not explain why\n",
    "# (1 point) The student attempts to answer but is way off\n",
    "# (0 points) The student does not attempt to answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 3\", and push the changes to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "<a id=\"part4\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## Part 4: Support Vector Machine Analysis (14 points)\n",
    "\n",
    "**&#9989; (4 points) Task 4.1:** Implement an SVM classifier with RBF kernel:\n",
    "- Initialize an SVM model with RBF kernel (1 point)\n",
    "- Define a grid of hyperparameters to search (C and gamma) (2 points)\n",
    "- Use the option `cv = 5` when fitting (This is 5-fold cross-validation to find the optimal parameters) (1 point)\n",
    "- Report the best parameters found and the cross-validation score (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:22:14.395392Z",
     "start_time": "2022-12-07T03:22:14.392835Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize SVM with default parameters\n",
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (8 points) Task 4.3:** Evaluate the optimized SVM model:\n",
    "- Train the model with the best parameters on the training data (2 points)\n",
    "- Make predictions on the test set (1 point)\n",
    "- Create a confusion matrix (1 point)\n",
    "- Display the confusion matrix using a heatmap with Blues colormap (2 points)\n",
    "- Calculate and print accuracy, precision, recall (2 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "\n",
    "# ----------- Train ------------- (2 points)\n",
    "# Create a model with the best parameters\n",
    "best_svm = SVC(kernel='rbf', \n",
    "               C=best_params['C'], \n",
    "               gamma=best_params['gamma'],\n",
    "               probability=True, \n",
    "               random_state=42)\n",
    "\n",
    "# Fit the optimized model\n",
    "best_svm.fit(X_train, y_train)\n",
    "\n",
    "# ----------- Predict ------------- (1 points)\n",
    "# Make predictions on test data\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "# ----------- Confusion Matrix ------------- (1 points)\n",
    "# Create confusion matrix\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# ------------ Visualize confusion matrix ------------- (2 points)\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_svm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Low MPG', 'High MPG'],\n",
    "            yticklabels=['Low MPG', 'High MPG'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - SVM with RBF Kernel')\n",
    "# plt.savefig('svm_confusion_matrix.png')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# ----------- Performance Metrics ------------- (2 points)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"\\nSVM Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_svm:.4f}\")\n",
    "print(f\"Precision: {precision_svm:.4f}\")\n",
    "print(f\"Recall: {recall_svm:.4f}\")\n",
    "print(f\"F1 Score: {f1_svm:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (SVM):\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 4\", and push the changes to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id=\"part5\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## Part 5: Model Comparison and Conclusion (8 points)\n",
    "\n",
    "**&#9989; (4 points) Task 5.1:** Compare the performance of the logistic regression and SVM models:\n",
    "- Create a side-by-side comparison of confusion matrices (2 points)\n",
    "- Make an histogram comparing accuracy, precision, recall (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER\n",
    "# \n",
    "# # Create a side-by-side comparison of confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Logistic Regression confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Low MPG', 'High MPG'],\n",
    "            yticklabels=['Low MPG', 'High MPG'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - Logistic Regression')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# SVM confusion matrix\n",
    "sns.heatmap(conf_matrix_svm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Low MPG', 'High MPG'],\n",
    "            yticklabels=['Low MPG', 'High MPG'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix - SVM with RBF Kernel')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('model_comparison_confusion_matrices.png')\n",
    "# plt.show()\n",
    "\n",
    "# Compare performance metrics in a table\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Logistic Regression': [accuracy, precision, recall, f1],\n",
    "    'SVM': [accuracy_svm, precision_svm, recall_svm, f1_svm],\n",
    "    'Difference (SVM - LR)': [accuracy_svm - accuracy, \n",
    "                              precision_svm - precision, \n",
    "                              recall_svm - recall, \n",
    "                              f1_svm - f1]\n",
    "})\n",
    "\n",
    "# print(\"\\nModel Performance Comparison:\")\n",
    "# print(metrics_comparison)\n",
    "\n",
    "# Visualize metrics comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.35\n",
    "index = np.arange(4)\n",
    "\n",
    "plt.bar(index, metrics_comparison['Logistic Regression'], bar_width,\n",
    "        label='Logistic Regression', color='lightblue')\n",
    "plt.bar(index + bar_width, metrics_comparison['SVM'], bar_width,\n",
    "        label='SVM', color='salmon')\n",
    "\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(index + bar_width / 2, metrics_comparison['Metric'])\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, alpha=0.3)\n",
    "# plt.savefig('model_performance_comparison.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (2 points) Task 5.2:** Explain which model you would recommend for this classification task and why:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 5\", and push the changes to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "---\n",
    "<a id=\"part6\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 6. Conceptual Questions (10 Points)\n",
    "\n",
    "The following questions probe your understanding of  `recall` and `precision`. You’ll be given a specific scenario, and you will need to decide whether to select a Machine Learning model that maximizes `recall` or `precision`.\n",
    "\n",
    "\n",
    "**&#9989; Question 6.1 (4 points):**  A new disease has been detected in Sweden. Doctors have taken multiple measurements of patients and passed them along to you. You’ve tested various models to predict which patients have the new disease. The Swedish health experts have told you it is critical that they identify **all** of the patients with the new disease so they can put them into quarantine. They tell you that it doesn’t matter if your model accidentally flags some people as having the disease even when they don’t, as it’s much better to tell people who aren’t sick to quarantine than to tell a sick person they don’t need to quarantine.\n",
    "\n",
    "Given this situation, should you choose the model that maximizes `recall` or the model that maximizes `precision`? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**&#9989; Question 6.2 (4 points):**\n",
    "You are working for the state of Michigan, helping them with their new unemployment insurance program. You’ve created various models that are meant to detect fraud–i.e., determine whether or not someone applied for unemployment insurance when they shouldn’t have. Your boss tells you that it’s critical that your model doesn’t accidentally accuse an innocent person of fraud. They say it’s fine if your model misses some people who committed fraud as long as there are no false accusations. \n",
    "\n",
    "Given this situation, should you choose the model that maximizes `recall` or the model that maximizes `precision`? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!** (2 points)\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 6\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id=\"conclusion\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 7. Conclusion (3 points)\n",
    "\n",
    "Make sure all of your changes to your repository are committed and pushed to GitHub. \n",
    "Before you leave\n",
    "\n",
    "1. Have you added your name and github username at the top of this notebook? ? (1 point)\n",
    "\n",
    "2. Push the changes to your GitHub repository (1 point)\n",
    "\n",
    "3. Upload your notebook to D2L in case something went wrong with your repository or if you couldn't get the repository to work.  (1 point)\n",
    "   \n",
    "4. Before submitting the notebook make sure to Restart your kernel and Run all cells. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Final\n",
    "\n",
    "![Moira2](https://media.giphy.com/media/d1E2HnwywoTkES08/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#169; Copyright 2022,  Department of Computational Mathematics, Science and Engineering at Michigan State University"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmse802",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
