{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER (for making sure this gets removed)\n",
    "\n",
    "# Grading Rubric (90 points total)\n",
    "\n",
    "## Part 1 (9 points)\n",
    "* 3 points for creating the GitHub repository directory\n",
    "* 3 points for correctly writing the cloning command\n",
    "* 3 points for having periodic commits with reasonable commit messages\n",
    "\n",
    "## Part 2 (25 points)\n",
    "\n",
    "* **Question 2.1** (2 points):\n",
    "  * 1 point for reading the dataset into `Pandas`\n",
    "  * 1 point for displaying the head and tail of the `DataFrame`\n",
    "* **Question 2.2** (3 points):\n",
    "  * 1 point for creating an undirected graph (`nx.Graph()`)\n",
    "  * 1 point for looping over the rows of the `DataFrame`\n",
    "  * 1 points for adding edges for every line in the `DataFrame`\n",
    "* **Question 2.3** (6 points):\n",
    "  * 1 point for drawing the graph\n",
    "  * 1 point for making a large figure (bigger than the matplotlib default)\n",
    "  * 1 point for adding node labels\n",
    "  * 1 point for having different colored nodes\n",
    "  * 2 points for correctly using the degree of the node to decide which color to use\n",
    "* **Question 2.4.1** (1 point):\n",
    "  * 1 point for finding the right function and using it correctly\n",
    "* **Question 2.4.2** (1 point):\n",
    "  * 1 point for finding the right function and using it correctly\n",
    "* **Question 2.4.3** (1 point):\n",
    "  * 1 point for finding the right function and using it correctly\n",
    "* **Question 2.4.4** (1 point):\n",
    "  * 1 point for using the two functions correctly\n",
    "* **Question 2.4.5** (2 points):\n",
    "  * 1 point for finding the correct function\n",
    "  * 1 point for using it correctly\n",
    "* **Question 2.4.6** (4 points):\n",
    "  * 1 point for looping through characters/nodes\n",
    "  * 1 point for computing distance for each characters/nodes\n",
    "  * 2 points for finding maximum distance\n",
    "* **Question 2.4.7** (4 points):\n",
    "  * 1 point for looping through characters/nodes\n",
    "  * 1 point for computing distance for each characters/nodes\n",
    "  * 2 points for finding character with maximum distance\n",
    "  \n",
    "## Part 3 (27 points)\n",
    "\n",
    "* **Question 3.1** (1 point):\n",
    "  * 1 point for a correct plot (axes labels and title not necessary)\n",
    "* **Question 3.2** (2 points):\n",
    "  * 1 point for answering \"no\"\n",
    "  * 1 point for some sort of justification\n",
    "* **Question 3.3** (4 points):\n",
    "  * 1 points for adding the constant\n",
    "  * 1 point for using `OLS()` correctly\n",
    "  * 1 point for using `fit()` correctly\n",
    "  * 1 point for displaying the `summary()` correctly\n",
    "* **Question 3.4** (2 points):\n",
    "  * 1 point for giving any linear equation\n",
    "  * 1 point for giving the correct best fit linear model\n",
    "* **Question 3.5** (5 points):\n",
    "  * 3 points for forming the dataframe\n",
    "  * 2 points for using `OLS()`, `fit()`, and `summary()` correctly\n",
    "* **Question 3.6** (2 points):\n",
    "  * 1 point for answering \"yes\"\n",
    "  * 1 point for correct justification (R^2 value or other)\n",
    "* **Question 3.7** (2 points):\n",
    "  * 1 point for correctly identifying which features are significant or not significant\n",
    "  * 1 point for correct justification based on the statistical summary (p-value or other)\n",
    "* **Question 3.8** (2 points):\n",
    "  * 2 points for an answer that sounds coherent and mostly correct\n",
    "  * 1 point if their answer either mentions even/odd symmetry (but is incoherent or incorrect)\n",
    "* **Question 3.9** (5 points):\n",
    "  * 3 points for forming the dataframe\n",
    "  * 2 points for using `OLS()`, `fit()`, and `summary()` correctly\n",
    "* **Question 3.10** (2 points):\n",
    "  * 1 point for stating that it performs almost as well as the full model\n",
    "  * 1 point for correct justification (R^2 value or other)\n",
    "  \n",
    "## Part 4 (29 points)\n",
    "\n",
    "* **Question 4.1** (2 points):\n",
    "  * 1 point for reading the dataset into `Pandas`\n",
    "  * 1 point for displaying the head and tail of the `DataFrame`\n",
    "* **Question 4.2** (2 points):\n",
    "  * 1 point for forming the features\n",
    "  * 1 point for forming the labels\n",
    "* **Question 4.3** (4 points):\n",
    "  * 2 points for creating the train-test split\n",
    "  * 1 point for using the correct `train_size` and `random_state`\n",
    "  * 1 point for printing the shapes of the four variables\n",
    "* **Question 4.4** (6 points):\n",
    "  * 1 point for fitting the SVC\n",
    "  * 1 point for using a `linear` kernel and `C=0.001`\n",
    "  * 1 point for using the training set for fitting (not the full set or the testing set)\n",
    "  * 1 point for predicting\n",
    "  * 1 point for predicting on the testing set (not the training set or full set)\n",
    "  * 1 point for printing both the `confusion_matrix` and the `classification_report`\n",
    "* **Question 4.5** (3 points):\n",
    "  * 1 point for repeating the code from Question 4.4\n",
    "  * 1 point for changing the value of `C`\n",
    "* **Question 4.6** (3 points):\n",
    "  * 2 points for stating the number of misclassifications\n",
    "  * 1 point for explaining they added up off-diagonal entries\n",
    "  * 1 point for stating the correct precision and recall numbers for the `Canadian` class\n",
    "  * 1 point for explaining what the precision means\n",
    "  * 1 point for explaining what the recall means\n",
    "* **Question 4.7** (1 point):\n",
    "  * 1 point for mentioning `GridSearchCV` in some manner\n",
    "* **Question 4.8** (3 points):\n",
    "  * 1 point for the correct answer\n",
    "  * 2 points for justifying it\n",
    "* **Question 4.9** (3 points):\n",
    "  * 1 point for the correct answer\n",
    "  * 2 points for justifying it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: right;\"> &#9989; Put your name here</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Final (Section 002 - Spring 2024) (90 points total)\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed having now finished CMSE 202. In particular, you'll be committing and pushing repository changes to a GitHub repository, working with data to build a network graph, performing regression analysis, and classifying data using a machine learning classifier. You should find that you have all of the skills necessary to complete this exam having completed the second half of CMSE 202!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. Once you've read through it, you'll probably want to make sure you do Part 1 first to ensure that your GitHub repository is working correctly. Let your instructor know right away if you run into issues!\n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. You can also use _your version_ of past CMSE 202 assignments and the CMSE 202 course materials as a resource! **However: The use of any person-to-person communication software or generative AI tools is absolutely not acceptable.** If you are seen accessing your email, using a collaborative cloud storage or document software (e.g. Slack, Google Documents), or generative AIs (e.g. ChatGPT), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**Keep your eyes on your screen!** Unfortunately, there isn't enough space in the room for everyone to sit at their own table so please do your best to keep your eyes on your own screen. This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 0: Academic integrity statement\n",
    "\n",
    "Read the following statement and edit the markdown text to put your name in the statement. This is your commitment to doing your own authentic work on this exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I, **INSERT NAME HERE**, affirm that this exam represents my own authetic work, without the use of any unpermitted aids or resources or person-to-person communication. I understand that this exam an an opportunity to showcase my own progress in developing and improving my computational skills and have done my best to demonstrate those skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 1: Add to your Git repository to track your progress on your exam (9 points)\n",
    "\n",
    "Before you get to far along in the exam, you're going to add it to the `cmse202-s24-turnin` repository you created in class so that you can track your progress on the exam and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "1. Navigate to your `cmse202-s24-turnin` repository and create a new directory called `final`.\n",
    "2. Move this notebook into that **new directory** in your repository, then **add it and commit it to your repository**.\n",
    "1. Finally, to test that everything is working, \"git push\" the file so that it ends up in your GitHub repository.\n",
    "\n",
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" respository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the noteobok, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-s24-turnin`\" repository inside the `final` directory that you just created. Periodically, **you'll be asked to commit your changes to the repository and push them to the remote GitHub location**. Of course, you can always commit your changes more often than that, if you wish.  It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the project for a bit.\n",
    "\n",
    "&#9989; **Do this**: Before you move on, put the command that your instructor should run to clone your repository in the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "# Put the command for cloning your repository here!\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 2: Graph for Game of Thrones (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER (for making sure this gets removed)\n",
    "\n",
    "#### Instructor information\n",
    "\n",
    "The goals for this part of the exam are for students to do the following:\n",
    "\n",
    "1. Use a provided dataset to create a simple network graph using networkx.\n",
    "2. Perform some basic analysis using the graph.\n",
    "\n",
    "This component of the exam should be similar to the sorts of things they we asked to do in Part 3 of Homework 2, but be careful about having them doing anything too complicated with the graph or ensure that there is clear documentation that they should be able to find to figure out what they need to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will look at characters in the book series \"A Song of Ice and Fire\" (\"A Game of Thrones\") by George R. R. Martin, specifically the book \"A Storm of Swords\". The series features a large number of characters in a variety of places around a fantasy world. Some of them appear with each other, while others never meet. We will model these character coappearances as an undirected graph. Every node will be a character and there will be a edge between two characters if they co-appeared (defined as: \"their names appear within 15 words of each other in the text\"). More info about this dataset can be found here https://github.com/melaniewalsh/sample-social-network-datasets/tree/master/sample-datasets/game-of-thrones\n",
    "\n",
    "To get started, download the `GameOfThrones.csv` file from the link below (or D2L) and place it in the same directory as your notebook. \n",
    "\n",
    "`https://raw.githubusercontent.com/skarnik1337/cmse202sec002s24final/main/GameOfThrones.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.1 (2 points)**: Read in the `GameOfThrones.csv` dataset into a `Pandas` `DataFrame` and display the first and last few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.1 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import pandas as pd\n",
    "GameOfThrones = pd.read_csv('GameOfThrones.csv')\n",
    "GameOfThrones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see two columns: `Character1` and `Character2`. Each row contains a pair of characters that coappeared. We will now create an **undirected graph** using this dataset.\n",
    "\n",
    "&#9989; **Question 2.2 (3 points)**: Create a `networkx` `Graph` object which has a vertex for each character and an edge between any pair of characters which are coappear. The resulting graph should now have an edge per row in the dataset and the set of all names should be the set of all nodes.\n",
    "\n",
    "One way to do this is to start with an empty `Graph`. Then, loop through each row of the dataset and add an edge between the two characters listed in that row. There are of course other solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.2 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "for i,row in GameOfThrones.iterrows():\n",
    "    G.add_edge(row.Character1,row.Character2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now visualize the graph.\n",
    "\n",
    "&#9989; **Question 2.3 (6 points)**: Using the `draw_networkx()` method, draw the graph. Then, make the following modifications to the drawing:\n",
    "\n",
    "1. Make a large `matplotlib` figure so that the graph is bigger and easier to look at.\n",
    "2. Label each vertex with the name of the character.\n",
    "3. Pick two different colors. Any node whose degree is at least 18 should be one color and all other nodes should be the other color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.3 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "colors = []\n",
    "for character in G:\n",
    "    if(G.degree(character) >= 18):\n",
    "        colors.append('r')\n",
    "    else:\n",
    "        colors.append('b')\n",
    "\n",
    "nx.draw_networkx(G,node_color=colors, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### For each part of Question 2.4, use a short amount of networkx code to find answer. Note that you must use the `Graph` object you created along with a networkx method to receive credit, and answers based on using the original csv file, the DataFrame, or the plot in Question 2.3 will not receive credit.\n",
    "\n",
    "Note that your code doesn't need to format the answer in a complete sentence, but the output should not contain any extraneous information.\n",
    "\n",
    "Also, if you couldn't create the `Graph` correctly, you can still receive credit on each part of Question 2.4 by writing code that would have given the correct answer if your `Graph` was correct.\n",
    "\n",
    "&#9989; **Question 2.4.1 (1 point)** How many characters are in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.1 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.4.2 (1 point)** True or False?: The characters `Ilyn` and `Joffrey` coappear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.2 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "G.has_edge(\"Ilyn\",\"Joffrey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.4.3 (1 point)** How many characters coappear with `Daenerys`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.3 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "G.degree(\"Daenerys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.4.4 (1 point)** List all characters who coappear with `Rickon`. \n",
    "\n",
    "**Hint**: The `list()` method and the `all_neighbors()` method in `networkx` will be useful for answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.4 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "list(nx.all_neighbors(G,\"Rickon\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the distance between two characters as the length of the shortest path between the nodes corresponding to the two characters (i.e. the number of edges in this path, which is one less than the number of nodes).\n",
    "\n",
    "&#9989; **Question 2.4.5 (2 points)**:  What is the distance between `Drogo` and `Walton`?\n",
    "\n",
    "**Hint**: See if you can use a search engine to find a `networkx` method that computes the length of the shortest path between two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.5 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "nx.shortest_path_length(G,\"Drogo\",\"Walton\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.4.6 (4 points)**: What is the **maximum distance** between a Game of Thrones character and `Robert`?\n",
    "\n",
    "**Hint**: You may want to start by looping through the nodes in the `Graph` you created, computing the distance between that node and `Robert`, and then appending that distance to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.6 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "distances2Robert = []\n",
    "for character in G:\n",
    "    distances2Robert.append(nx.shortest_path_length(G,\"Robert\",character))\n",
    "max(distances2Robert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.4.7 (4 points)**: Which Game of Thrones **character** is farthest from `Lancel` (i.e. which character has the greatest distance to `Lancel`)? \n",
    "\n",
    "**Note**: You may assume there is a unique farthest character (i.e. no ties for the greatest distance).\n",
    "\n",
    "**Hint**: Similarly to Question 2.4.7, you may want to start by looping through the nodes in the `Graph` you created, computing the distance between that node and `Lancel`, and then appending that distance to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 2.4.6 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import numpy as np\n",
    "distances2Lancel = []\n",
    "for character in G:\n",
    "    distances2Lancel.append(nx.shortest_path_length(G,\"Lancel\",character))\n",
    "list(G.nodes)[np.argmax(distances2Lancel)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 2**\", and push the changes to GitHub.\n",
    "\n",
    "\n",
    "If committing and/or pushing isn't working for you, write down the complete commands in this cell that would have committed your changes (with the commit message) and pushed them to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 3: Regression on synthetic data (27 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER (for making sure this gets removed)\n",
    "\n",
    "#### Instructor information\n",
    "\n",
    "The goals for this part of the exam are for students to do the following:\n",
    "\n",
    "1. Use a provided dataset to perform linear/multiple/logistic regression using statsmodels.\n",
    "2. Answer conceptual questions to indicate they can correctly interpret the results (e.g. how good is the fit? what as the important features (regressors) for the regression model?)\n",
    "\n",
    "This component of the exam should involve things connected to Parts 3, 4, and 5 of Homework #3. The things students are being asked to do should be pretty simple and **careful attention should be paid to making sure this works on JupyterHub**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will generate synthetic data according to a known model. First, you will perform linear regression on the data and interperate the results. Next, you will perform polynomial regression and interperate the results. Finally, you will perform polynomial regression, but with a reduced model, and interperate the results.\n",
    "\n",
    "\n",
    "To get started, run the cell below to generate two `numpy` arrays `x_data` and `y_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# DO NOT EDIT THIS CELL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "x_data = np.random.uniform(-1,1,size=(101,))\n",
    "y_data = np.sin(np.pi*x_data)+0.15*np.random.normal(size=(101,))\n",
    "# DO NOT EDIT THIS CELL\n",
    "# DO NOT EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.1 (1 point)**: Before you get too caried away with regression analysis, make a scatterplot of this data with `y_data` on the vertical axis and `x_data` on the horizontal axis. This will help you see what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code for Question 3.1 here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_data,y_data,'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.2 (2 points)**: Looking at the plot you made in Question 3.1, is a linear model appropriate for this data? Briefly justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "No, since the data appears to form a sinusoidal pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.3 (4 points)**: Regardless of your answer to Question 3.2, we will try linear regression anyway.\n",
    "\n",
    "**Do This**: Using `OLS()` in `statsmodels`, fit a linear model of the form $\\widehat{y} = Ax+B$ to the data. \n",
    "\n",
    "*Hint*: Don't forget the constant term. Also, you might want to have the original variable `x_data` handy for Question 3.5, so be careful not to overwrite it when using the `add_constant()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code for Question 3.3 here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import statsmodels.api as sm\n",
    "x_withconst = sm.add_constant(x_data)\n",
    "linear_model = sm.OLS(y_data,x_withconst)\n",
    "results_linear_model = linear_model.fit()\n",
    "results_linear_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.4 (2 points)**: Looking at the results summary, what is the equation of your best fit linear model? You may round the coefficents to a few decimal places when writing down your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "$y = 0.9343x+0.0276$ (This answer may vary if they have a different version of Python with a different RNG and different data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.5 (5 points)**: Now, we will use OLS to fit a degree-$6$ polynomial model to this data. If you get stuck, you may want to look at the Day-14 PCA. \n",
    "\n",
    "**Do the following**: \n",
    "* First, construct a `Pandas` `DataFrame` whose columns are the monomial features $1, x, x^2, x^3, x^4, x^5, x^6$. In other words, this `DataFrame` should have 7 columns. The 0th column has all 1's. The 1st column should have the values in `x_data`. The 2nd column should have the values in `x_data` raised to the 2nd power, ..., and the 6th column should have the values in `x_data` raised to the 6th power.\n",
    "* Then, perform OLS using `statsmodels`, and display the results summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code for Question 3.5 here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "df_poly = pd.DataFrame({\"x0\":x_data**0,\"x\":x_data,\"x2\":x_data**2,\"x3\":x_data**3,\"x4\":x_data**4,\"x5\":x_data**5,\"x6\":x_data**6})\n",
    "poly_model = sm.OLS(y_data,df_poly)\n",
    "results_poly_model = poly_model.fit()\n",
    "results_poly_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.6 (2 points)**: Looking at just the results summaries in Question 3.5 and Question 3.3, is our degree-$6$ polynomial significantly better than our linear model? **Justify your answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "Yes, the degree-6 polynomial was much better than the linear model. The polynomial model had an $R^2$ value of $0.965$, while the linear model had an $R^2$ value of $0.591$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.7 (2 points)**: Looking at just the results summary in Question 3.5 (and not at how the synthetic data was generated), which of the monomial features $1, x, x^2, x^3, x^4, x^5, x^6$ are statistically significant and which are not statistically significant? **Again, justify your answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "The $x$, $x^3$, and $x^5$ features were statistically significant while the $1$, $x^2$, $x^4$, and $x^6$ features were not statistically significant. (Look at the $p$-values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.8 (2 points)**: In Question 3.7, you should have observed a pattern to which monomial features were statistically significant and which were not. The data points $(x_i,y_i)$ were generated according to the sinusoidal model $y_i = \\sin(\\pi x_i) + \\text{noise}_i$. With this in mind, give an explaination for this pattern.\n",
    "\n",
    "*Hint*: Think about what kind of symmetry $y = \\sin(\\pi x)$ has about $x = 0$ as well as what kind of symmetry each of the monomials $1, x, x^2, x^3, x^4, x^5, x^6$ has about $x = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "The function $\\sin(\\pi x)$ is odd. So the odd monomial features ($x, x^3, x^5$) naturally do a better job describing the underlying relationship between $x$ and $y$ than the even monomial features ($1, x^2, x^4, x^6$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.9 (5 points)**: Now, use OLS to fit a polynomial model using only the monomial features which you identified as being statistically significant. Again, print out the results summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code for Question 3.9 here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "df_odd = pd.DataFrame({\"x\":x_data,\"x3\":x_data**3,\"x5\":x_data**5})\n",
    "odd_model = sm.OLS(y_data,df_odd)\n",
    "results_odd_model = odd_model.fit()\n",
    "results_odd_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **Question 3.10 (2 points)**: How well did your reduced polynomial model (from Question 3.9) fit the data compared to the full degree-$6$ polynomial model (from Question 3.5)? Give some quantitative justification for this answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell and put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "The reduced model ($R^2 = 0.963$) is nearly as good of a fit as the full model ($R^2 = 0.965$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 3**\", and push the changes to GitHub.\n",
    "\n",
    "\n",
    "If committing and/or pushing isn't working for you, write down the complete commands in this cell that would have committed your changes (with the commit message) and pushed them to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 4: Support vector machine (SVM) classification (29 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER (for making sure this gets removed)\n",
    "\n",
    "#### Instructor information\n",
    "\n",
    "The goals for this part of the exam are for students to do the following:\n",
    "\n",
    "1. Perform a train-test split of data\n",
    "2. Answer conceptual questions about the data using some of the terminology using in ML (e.g. what are features? what are labels? what are samples? etc.)\n",
    "3. Fit an SVM classifier to training data and then run a prediction on testing data\n",
    "4. Interpret the outputs of the classification report and confusion matrix.\n",
    "\n",
    "This component of the exam should mirror what they were expected to do in Homework 4, but pulling in PCA is probably not necessarily unless it's well-scaffolded and is fairly straightforward to do with the data... Also, it probably doesn't make sense to do anything with the Perceptron model for the purposes of the exam. And, again, **make sure this works on JupyterHub**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will use a support vector machine (SVM) classifier to identify seed varieties based on various seed measurements. We will be using the UC Irvine Machine Learning Repository Seeds Dataset. More info about this dataset can be found here https://archive.ics.uci.edu/dataset/236/seeds. \n",
    "\n",
    "To get started, download the `Seeds.csv` file from the link below (or D2L) and place it in the same directory as your notebook. \n",
    "\n",
    "`https://raw.githubusercontent.com/skarnik1337/cmse202sec002s24final/main/Seeds.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.1 (2 points)**: Read in the `Seeds.csv` dataset into a `Pandas` `DataFrame` and display the first and last few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 4.1 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import pandas as pd\n",
    "seeds_df = pd.read_csv('Seeds.csv')\n",
    "seeds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.2 (2 points)**: Our goal is to classify the `Variety` of the seed given the features `Area`, `Perimeter`, `Compactness`, `Kernel Length`, `Kernel Width`, `Asymmerty` and `Groove Length`. Create a variable with all of the columns of the `DataFrame` except for `Variety`,  and another variable with just the `Variety` column of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 4.2 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "seed_features = seeds_df.drop(columns=['Variety'])\n",
    "seed_labels = seeds_df['Variety']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is properly loaded into Python, we need to perform a **train-test-split** so that we can build our SVM classifier and test it.\n",
    "\n",
    "&#9989; **Question 4.3 (4 points)**: Use the `train_test_split()` method from `sklearn.model_selection` like we did in class. Use a `train_size` of `0.75` and `random_state` of `161803`. You should now have training features, testing features, training labels, and testing labels. Finally, **print the shape of your training features, training labels, testing features, and testing labels** to verify that your train-test-split did what it was supposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 4.2 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(seed_features, seed_labels, train_size=0.75, random_state=161803)\n",
    "print(features_train.shape)\n",
    "print(labels_train.shape)\n",
    "print(features_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.4 (6 points)**: Fit an SVM classifier (using the `sklearn` `SVC` class) to the dataset. Use a `linear` kernel and set the hyper-parameter to be `C=0.001.` Then **fit the SVM using your training set** and use the resulting SVM to **predict the labels for the testing set** so you get predicted labels for the testing set. Finally, **print the fit statistics** using the `confusion_matrix()` and `classification_report()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 4.4 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='linear', C=0.001)\n",
    "svc.fit(features_train, labels_train)\n",
    "\n",
    "labels_predict = svc.predict(features_test)\n",
    "\n",
    "print(confusion_matrix(labels_test,labels_predict))\n",
    "print(classification_report(labels_test,labels_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.5 (2 points)**: Create a second SVM classifier and test it by repeating your work from Question 4.4, but this time set the hyper-parameter to be `C=100.` Again, **print the fit statistics** using the `confusion_matrix()` and `classification_report()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 4.5 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "svc2 = SVC(kernel='linear', C=100)\n",
    "svc2.fit(features_train, labels_train)\n",
    "\n",
    "labels_predict2 = svc2.predict(features_test)\n",
    "\n",
    "print(confusion_matrix(labels_test,labels_predict2))\n",
    "print(classification_report(labels_test,labels_predict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.6 (6 points)**: Interpret the outputs of your classification reports and the confusion matrices by answering these questions (provide at least a couple sentences each for full credit): \n",
    "\n",
    "* Of the 53 seeds in the testing set, how many were misclassified by the first SVM (`C = 0.001`)? How many were misclassified by the second SVM (`C = 100`)? **Explain how you figured out the number of misclassifications**. \n",
    "\n",
    "* For just the first SVM (`C = 0.001`) what were the **precision** and **recall** for just the `Canadian` class? Explain in complete sentences what both of these numbers mean **in the context of this dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "* The first SVM had $14+1+2 = 17$ misclassifications while the second SVM had $1+2 = 3$ misclassifications. This is figured out by adding the off-diagonal elements in the confusion matrix.\n",
    "\n",
    "* For the first classifier, the precision for `Canadian` seeds was $1.00$, and the recall for `Canadian` seeds was $0.30$. A precision of $1.00$ means that every seed that was classified as `Canadian` was actually a `Canadian` seed. A recall of $0.30$ means that $30\\%$ of `Canadian` seeds were correctly classified as a `Canadian` seed.\n",
    "\n",
    "(Students might have slightly different results if they did their train-test-split differently or have a different version of Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "&#9989; **Question 4.7 (1 point)**: Suppose we wanted to try fitting a Support Vector Classifier for multiple choices of the kernel function and multiple choices for the values of the hyperparameter(s) (instead of just using a `linear` kernel with one value of `C`). We could write code with nested for loops to repeat the procedure with every combination of kernel function and hyperparameter value(s) we wanted to try. Name a method built into sklearn that will do this automatically. (We used this on an in-class assignment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "sklearn.model_selection.GridSearchCV or just GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.8 (3 points)**: Both of the images below show the same two-dimensional dataset with two classes (solid blue squares and unfilled red circles) along with the decision boundary of a linear classifier. One classifier was generated via the Perceptron Learning Algorithm, and the other used a Support Vector Classifier. Which one is which? **Justify your answer!**\n",
    "\n",
    "Classifier A          | | Classifier B\n",
    ":-------------------------:|:---:|:-------------------------:\n",
    "![](https://i.ibb.co/R2BBsDC/Datapoints1-A.png)  | |  ![](https://i.ibb.co/mb9vcq4/Datapoints1-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "Classifier A (left) used the PLA while Classifier B (right) used SVC. Both classifiers have zero errors, but Classifier B has a larger margin. Hence, Classifier A cannot be the SVC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.9 (3 points)**: Both of the images below show the same two-dimensional dataset with two classes (solid blue squares and unfilled red circles) along with the decision boundary of a linear Support Vector Classifier. One used the hyperparameter `C = 0.1`, and the other used the hyperparameter `C = 1000`. Which one is which? **Justify your answer!**\n",
    "\n",
    "Classifier X          | | Classifier Y\n",
    ":-------------------------:|:---:|:-------------------------:\n",
    "![](https://i.ibb.co/7pPCRwh/Datapoints2-A.png)  | |  ![](https://i.ibb.co/LSMBXzd/Datapoints2-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "Classifier X (left) used `C=1000` while Classifier Y (right) used `C=0.1`. Classifier X found a line with a small margin, but no misclassifications, i.e. it overfit the data. Classifier Y found a line with a bigger margin but some violations of this margin. Hence, Classifier X used a larger value of C to heavily penalize violating the margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 4**\", and push the changes to GitHub.\n",
    "\n",
    "\n",
    "If committing and/or pushing isn't working for you, write down the complete commands in this cell that would have committed your changes (with the commit message) and pushed them to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Final!\n",
    "\n",
    "Make sure all of your changes to your repository are committed and pushed to GitHub (or that you wrote down the commands that would have done that after each part). Also upload a copy of this notebook to the dropbox on D2L in case something went wrong with your repository or if you couldn't get the repository to work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
