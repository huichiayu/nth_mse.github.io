{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: right;\"> &#9989; Put your name here</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Exam II (Section 003 - Fall 2024) (71 pts)\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed having now finished CMSE 202. In particular, you'll be showcasing your understanding of Git, performing regression analysis, and classifying data using a machine learning classifier. You should find that you have all of the skills necessary to complete this exam having completed the second half of CMSE 202!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. \n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. You can also use _your version_ of past CMSE 202 assignments and the CMSE 202 course materials as a resource! **However: The use of any person-to-person communication software or generative AI tools is absolutely not acceptable.** If you are seen accessing your email, using a collaborative cloud storage or document software (e.g. Slack, Google Documents), or generative AIs (e.g. ChatGPT), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**Keep your eyes on your screen!** Unfortunately, there isn't enough space in the room for everyone to sit at their own table so please keep your eyes on your own screen. This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These imports will be needed later. Run this cell, and do not edit it.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 0: Academic integrity statement (2 pts)\n",
    "\n",
    " Read the following statement and edit the markdown text to put your name in the statement. This is your commitment to doing your own authentic work on this exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I, <font size=+3>&#9998;</font>**INSERT NAME HERE**, affirm that this exam represents my own authetic work, without the use of any unpermitted aids or resources or person-to-person communication. I understand that this exam an an opportunity to showcase my own progress in developing and improving my computational skills and have done my best to demonstrate those skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Git (11 points)\n",
    "\n",
    "This part of the exam will check your understanding of using Git. To avoid merge conflicts and other issues, you will not actually be pushing anything to Github. Rather, you will just be writing the code you would use to accomplish the specified tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Write the sequence of Git commands that would you need to use in a terminal to produce the shown repository structure. Assume the commits encompass all the changes in files already tracked by Git (i.e., no new files are added as part of these commits) (3 pts). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/branching_scenario.png\" width=400px align=\"center\" style=\"margin-left: 20px\" alt=\"Git scenario\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 1.1 here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Explain what this command does: _git log --author=\"Iam Studious\" -p project.py_ (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 1.2 here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 (2 pts) Assume that you found a Git repository for an actively developed game that you really like, and that you would like to be involved in some capacity with the its future development. You think about two aspects that you might want to tackle: (a) The game has many features that you like, and others that you believe you can enhance. (b) You also have some ideas for setting the game in space instead of its current setting in medieval times. As a developer with limited time you can only choose one of the two aspects. Decide whether you want to pursue (a) or (b) (choose only one, either choice is fine), and based on your choice, **justify** whether you would proceed with your development using _git fork_, or with _git branch_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 1.3 here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 A pet walked across a keyboard while a Git terminal was open, and it very suspiciously caused certain Git commands to run as shown. For some reason (maybe due to those white rectangles), you cannot see the commands A, B, C, D that the pet ran, only the output of those commands. Based on the output, write the commands that the pet ran below. (4 pts) <br/>\n",
    "\n",
    "<font size=+3>&#9998;</font> **Write your answers for 1.4 next to A, B, C, D below**\n",
    "\n",
    "A        <br/>\n",
    "B        <br/>\n",
    "C        <br/>\n",
    "D        <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/git_commandline_problem.png\" width=\"80%\" alt=\"Terminal commands with some redacted commands labeled A, B, C, and D.\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Perform linear regression analysis on data (17 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file reg_data.csv contains information on the streamflow for 293 streamgages in the conterminous United States. The predictor variables are drawn from the GAGES-II data base, and the response variable is the the 90th percentile of annual maximum streamflow (see the file reg_data_readme.txt for details). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Load the data file into a pandas data frame. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 (6 pts) Using `OLS()` in `statsmodels`, fit a linear model using all 7 predictor variables and $y$-intercept $c$ of the form $\\text{max90} = a_1 * \\text{DRAIN\\_SQKM}+ a_2 * \\text{PPTAVG\\_BASIN} + a_3 * \\text{T\\_AVG\\_BASIN} + a_4 * \\text{T\\_AVG\\_SITE} + a_5 * \\text{RH\\_BASIN} + a_6 * \\text{MAR\\_PPT7100\\_CM} + a_7 * \\text{RRMEDIAN} + c$ to the data, where $a_1, a_2, \\ldots, a_7$ and $c$ are all constants.\n",
    "\n",
    "**Show the table of the resulting OLS Regression Results** \n",
    "\n",
    "*Hint*: Don't forget the constant term, see `add_constant()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 (2 pts) Based on the model you fit, an increase of one unit in RH_BASIN while holding all the other variables constant will lead to what expected increase in the outcome variable max90? You must justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 2.3 here**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 (2 pts) Comment on the goodness of fit of your model in terms of the coefficient of determination $R^2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 2.4 here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.1 (2 pts) Select only the significant featue(s) in the model based on their p-values, and fit again with the reduced features. \n",
    "\n",
    "**Hint:** Do not drop the constant term regardless of its $p$-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.2 (1pt) Report on any changes in $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 2.5.2 here**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.1 (2 pts) Let's transform the data, and only fit a model $\\log{(\\text{max90})} = a * \\log{(\\text{DRAIN\\_SQKM})} + c$. The data is already transformed for you in the code block below, just fit a model per the equation given, and obtain the resulting OLS regression results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasnform data - Do not edit\n",
    "x3 = np.log(df['DRAIN_SQKM'])\n",
    "x3 = sm.add_constant(x3)\n",
    "y3 = np.log(df['max90'])\n",
    "\n",
    "\n",
    "\n",
    "# Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.2 (1 pt) Does the fit improve with the data transformation? Why do you think that is the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 2.6.2 here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 3: Support vector machine (SVM) classification (29 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will use a support vector machine (SVM) classifier to identify seed varieties based on various seed measurements. We will be using the UC Irvine Machine Learning Repository Seeds Dataset. More info about this dataset can be found here https://archive.ics.uci.edu/dataset/236/seeds. \n",
    "\n",
    "To get started, download the `Seeds.csv` file from the link below (or D2L) and place it in the same directory as your notebook. \n",
    "\n",
    "`https://raw.githubusercontent.com/skarnik1337/cmse202sec002s24final/main/Seeds.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.1 (2 points)**: Read in the `Seeds.csv` dataset into a `Pandas` `DataFrame` and display the first and last few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 3.1 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.2 (2 points)**: Our goal is to classify the `Variety` of the seed given the features `Area`, `Perimeter`, `Compactness`, `Kernel Length`, `Kernel Width`, `Asymmerty` and `Groove Length`. Create a variable with all of the columns of the `DataFrame` except for `Variety`,  and another variable with just the `Variety` column of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 3.2 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is properly loaded into Python, we need to perform a **train-test-split** so that we can build our SVM classifier and test it.\n",
    "\n",
    "&#9989; **Question 3.3 (4 points)**: Use the `train_test_split()` method from `sklearn.model_selection` like we did in class. Use a `train_size` of `0.75` and `random_state` of `161803`. You should now have training features, testing features, training labels, and testing labels. Finally, **print the shape of your training features, training labels, testing features, and testing labels** to verify that your train-test-split did what it was supposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 3.3 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.4 (6 points)**: Fit an SVM classifier (using the `sklearn` `SVC` class) to the dataset. Use a `linear` kernel and set the hyper-parameter to be `C=0.001.` Then **fit the SVM using your training set** and use the resulting SVM to **predict the labels for the testing set** so you get predicted labels for the testing set. Finally, **print the fit statistics** using the `confusion_matrix()` and `classification_report()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 3.4 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.5 (2 points)**: Create a second SVM classifier and test it by repeating your work from Question 4.4, but this time set the hyper-parameter to be `C=100.` Again, **print the fit statistics** using the `confusion_matrix()` and `classification_report()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 3.5 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.6 (6 points)**: Interpret the outputs of your classification reports and the confusion matrices by answering these questions (provide at least a couple sentences each for full credit): \n",
    "\n",
    "* Of the 53 seeds in the testing set, how many were misclassified by the first SVM (`C = 0.001`)? How many were misclassified by the second SVM (`C = 100`)? **Explain how you figured out the number of misclassifications**. \n",
    "\n",
    "* For just the first SVM (`C = 0.001`) what were the **precision** and **recall** for just the `Canadian` class? Explain in complete sentences what both of these numbers mean **in the context of this dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "&#9989; **Question 3.7 (1 point)**: Suppose we wanted to try fitting a Support Vector Classifier for multiple choices of the kernel function and multiple choices for the values of the hyperparameter(s) (instead of just using a `linear` kernel with one value of `C`). We could write code with nested for loops to repeat the procedure with every combination of kernel function and hyperparameter value(s) we wanted to try. Name a method built into sklearn that will do this automatically. (We used this on an in-class assignment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.8 (3 points)**: Both of the images below show the same two-dimensional dataset with two classes (solid blue squares and unfilled red circles) along with the decision boundary of a linear classifier. One classifier was generated via the Perceptron Learning Algorithm, and the other used a Support Vector Classifier. Which one is which? **Justify your answer!**\n",
    "\n",
    "Classifier A          | | Classifier B\n",
    ":-------------------------:|:---:|:-------------------------:\n",
    "![](https://i.ibb.co/R2BBsDC/Datapoints1-A.png)  | |  ![](https://i.ibb.co/mb9vcq4/Datapoints1-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.9 (3 points)**: Both of the images below show the same two-dimensional dataset with two classes (solid blue squares and unfilled red circles) along with the decision boundary of a linear Support Vector Classifier. One used the hyperparameter `C = 0.1`, and the other used the hyperparameter `C = 1000`. Which one is which? **Justify your answer!**\n",
    "\n",
    "Classifier X          | | Classifier Y\n",
    ":-------------------------:|:---:|:-------------------------:\n",
    "![](https://i.ibb.co/7pPCRwh/Datapoints2-A.png)  | |  ![](https://i.ibb.co/LSMBXzd/Datapoints2-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 4: Logistic Regression Classification (12 points)\n",
    "\n",
    "The data for this part comes from the medical field, and it aims to fit a logisitic regression model that will predict whether an individual is likely to have diabetes or not based on a variety of predictor variables. See the file `diabetes_readme.txt` for more details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 (2 pts) Load the file `diabetes.csv` into a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 (3 pts) Split the dataset into training (75%) and testing (25%). \n",
    "\n",
    "Use the columns ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker','Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'HvyAlcoholConsump',\n",
    "       'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'Sex', 'Age', 'Income'] as your predictors, and the column 'Diabetes_binary' as your outcome variable. \n",
    "\n",
    "**Hint: Do not forget to add a constant to the feature vector using sm.add_constant()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 (3 pts) Use statsmodels to train a logistic classification model, and print the summary table of the logit regression results.\n",
    "\n",
    "**Hint: Do not forget to include the constant term to your training vector using sm.add_constant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 (2 pts) Use the .predict() method to create the predicted labels using the test input. Print the output.\n",
    "\n",
    "**Hint: the predicted output must be transformed to either 0 (no diabetes) or 1 (diabetes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 (2 pts) Use sklearn.metrics to obtain and print the accuracy_score on the 0/1 predicted versus test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Exam!\n",
    "\n",
    "Upload a copy of this notebook to the dropbox on D2L, and check in with instructional team before leaving the room."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
