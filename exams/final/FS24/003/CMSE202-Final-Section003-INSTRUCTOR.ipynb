{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: right;\"> &#9989; Put your name here</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Exam II (Section 003 - Fall 2024) (71 pts)\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed having now finished CMSE 202. In particular, you'll be showcasing your understanding of Git, performing regression analysis, and classifying data using a machine learning classifier. You should find that you have all of the skills necessary to complete this exam having completed the second half of CMSE 202!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. \n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. You can also use _your version_ of past CMSE 202 assignments and the CMSE 202 course materials as a resource! **However: The use of any person-to-person communication software or generative AI tools is absolutely not acceptable.** If you are seen accessing your email, using a collaborative cloud storage or document software (e.g. Slack, Google Documents), or generative AIs (e.g. ChatGPT), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**Keep your eyes on your screen!** Unfortunately, there isn't enough space in the room for everyone to sit at their own table so please keep your eyes on your own screen. This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These imports will be needed later. Run this cell, and do not edit it.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 0: Academic integrity statement (2 pts)\n",
    "\n",
    " Read the following statement and edit the markdown text to put your name in the statement. This is your commitment to doing your own authentic work on this exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I, <font size=+3>&#9998;</font>**INSERT NAME HERE**, affirm that this exam represents my own authetic work, without the use of any unpermitted aids or resources or person-to-person communication. I understand that this exam an an opportunity to showcase my own progress in developing and improving my computational skills and have done my best to demonstrate those skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Git (11 points)\n",
    "\n",
    "This part of the exam will check your understanding of using Git. To avoid merge conflicts and other issues, you will not actually be pushing anything to Github. Rather, you will just be writing the code you would use to accomplish the specified tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Write the sequence of Git commands that would you need to use in a terminal to produce the shown repository structure. Assume the commits encompass all the changes in files already tracked by Git (i.e., no new files are added as part of these commits) (3 pts). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/branching_scenario.png\" width=400px align=\"center\" style=\"margin-left: 20px\" alt=\"Git scenario\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 1.1 here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER (for making sure this gets removed)\n",
    "\n",
    "1.1 The sequence of Git commands that produces the shown repository structure are: <br/>\n",
    "_git branch mytest <br/>\n",
    "git checkout mytest <br/>\n",
    "git commit -m \"adder User class\" <br/>\n",
    "git commit -m \"Edited docstrings\" <br/>\n",
    "git checkout main <br/>\n",
    "git merge mytest_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Explain what this command does: _git log --author=\"Iam Studious\" -p project.py_ (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 1.2 here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER (for making sure this gets removed) \n",
    "\n",
    "1.2 The command _git log --author=\"Iam Studious\" -p project.py_ <br/>\n",
    "displays all the changes that Iam Studious has made to the file project.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 (2 pts) Assume that you found a Git repository for an actively developed game that you really like, and that you would like to be involved in some capacity with the its future development. You think about two aspects that you might want to tackle: (a) The game has many features that you like, and others that you believe you can enhance. (b) You also have some ideas for setting the game in space instead of its current setting in medieval times. As a developer with limited time you can only choose one of the two aspects. Decide whether you want to pursue (a) or (b) (choose only one, either choice is fine), and based on your choice, **justify** whether you would proceed with your development using _git fork_, or with _git branch_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 1.3 here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER (for making sure this gets removed) \n",
    "\n",
    "1.3 For (a), I would proceed with git branch, implement the changes I want, and then do a pull request to merge back into main. These changes do not completely change the scope of the game, so branching makes sense. <br/>\n",
    "    For (b), I would proceed with _git fork_, change the setting (which is a more fundamental change to the game). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 A pet walked across your keyboard while a Git terminal was open, and it very suspiciously caused certain Git commands to run as shown. For some reason (maybe due to those white rectangles), you cannot see the commands A, B, C, D that the pet ran, only the output of those commands. Based on the output, write the commands that the pet ran below. (4 pts) <br/>\n",
    "\n",
    "<font size=+3>&#9998;</font> **Write your answers for 1.4 next to A, B, C, D below**\n",
    "\n",
    "A        <br/>\n",
    "B        <br/>\n",
    "C        <br/>\n",
    "D        <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER (for making sure this gets removed) \n",
    "\n",
    "1.4 The redacted commands are: <br/>\n",
    "A _git init_       <br/>\n",
    "B _git status_       <br/>\n",
    "C _git branch development_       <br/>\n",
    "D _git log_       <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/git_commandline_problem.png\" width=\"80%\" alt=\"Terminal commands with some redacted commands labeled A, B, C, and D.\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Perform linear regression analysis on data (17 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file reg_data.csv contains information on the streamflow for 293 streamgages in the conterminous United States. The predictor variables are drawn from the GAGES-II data base, and the response variable is the the 90th percentile of annual maximum streamflow (see the file reg_data_readme.txt for details). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Load the data file into a pandas data frame. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "import os\n",
    "\n",
    "data_path = './data/'\n",
    "file_name = 'reg_data.csv'\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_path, file_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 (6 pts) Using `OLS()` in `statsmodels`, fit a linear model using all 7 predictor variables and $y$-intercept $c$ of the form $\\text{max90} = a_1 * \\text{DRAIN\\_SQKM}+ a_2 * \\text{PPTAVG\\_BASIN} + a_3 * \\text{T\\_AVG\\_BASIN} + a_4 * \\text{T\\_AVG\\_SITE} + a_5 * \\text{RH\\_BASIN} + a_6 * \\text{MAR\\_PPT7100\\_CM} + a_7 * \\text{RRMEDIAN} + c$ to the data, where $a_1, a_2, \\ldots, a_7$ and $c$ are all constants.\n",
    "\n",
    "**Show the table of the resulting OLS Regression Results** \n",
    "\n",
    "*Hint*: Don't forget the constant term, see `add_constant()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "x1 = df[['DRAIN_SQKM','PPTAVG_BASIN','T_AVG_BASIN','T_AVG_SITE','RH_BASIN','MAR_PPT7100_CM','RRMEDIAN']]\n",
    "y = df['max90']\n",
    "x1 = sm.add_constant(x1)\n",
    "\n",
    "## fit a OLS model with intercept on the predictor variables\n",
    "model1 = sm.OLS(y,x1)\n",
    "\n",
    "est1 = model1.fit() \n",
    "est1.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 (2 pts) Based on the model you fit, an increase of one unit in RH_BASIN while holding all the other variables constant will lead to what expected increase in the outcome variable max90? You must justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 2.3 here**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "An increase of one unit in RH_BASIN while holding all the otherr constant will lead to an estimated increase of 120.5. This is read from the value of the regression coefficient of RH_BASIN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 (2 pts) Comment on the goodness of fit of your model in terms of the coefficient of determination $R^2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 2.4 here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "The model has an $R^2$ of 0.292, which indicates that very little of the variability in the response is explained by the model. So the model is not a good fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.1 (2 pts) Select only the significant featue(s) in the model based on their p-values, and fit again with the reduced features. \n",
    "\n",
    "**Hint:** Do not drop the constant term regardless of its $p$-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "# Keeping only DRAIN_SQKM and refitting:\n",
    "\n",
    "x2 = df['DRAIN_SQKM']\n",
    "y = df['max90']\n",
    "x2 = sm.add_constant(x2)\n",
    "\n",
    "## fit a OLS model with intercept on the predictor variables\n",
    "model2 = sm.OLS(y,x2)\n",
    "\n",
    "est2 = model2.fit() \n",
    "est2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.2 (1pt) Report on any changes in $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 2.5.2 here**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "All variables except for DRAIN_SQKM have large p-values, indicating that they are not signficanct predictors for max90. However, fitting the model with only the constant term and DRAIN_SQKM lead to a drop in $R^2$ giving 0.101. So other predictors are important to the model despite their low $p$-value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.1 (2 pts) Let's transform the data, and only fit a model $\\log{(\\text{max90})} = a * \\log{(\\text{DRAIN\\_SQKM})} + c$. The data is already transformed for you in the code block below, just fit a model per the equation given, and obtain the resulting OLS regression results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasnform data - Do not edit\n",
    "x3 = np.log(df['DRAIN_SQKM'])\n",
    "x3 = sm.add_constant(x3)\n",
    "y3 = np.log(df['max90'])\n",
    "\n",
    "\n",
    "\n",
    "# Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "# fitting a linear model to log transformed max90 and DRAIN_SQKM\n",
    "\n",
    "# trasnform data - Do not edit\n",
    "x3 = np.log(df['DRAIN_SQKM'])\n",
    "y3 = np.log(df['max90'])\n",
    "x3 = sm.add_constant(x3)\n",
    "\n",
    "## fit a OLS model with intercept on the predictor variables\n",
    "model3 = sm.OLS(y3,x3)\n",
    "\n",
    "est3 = model3.fit() \n",
    "est3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.2 (1 pt) Does the fit improve with the data transformation? Why do you think that is the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Delete this content, and write your answer for 2.6.2 here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "Yes, the $R^2$ value went up to $0.502$. This indicates that the relationship between the outcome variable and the predictor is non-linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 3: Support vector machine (SVM) classification (29 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER (for making sure this gets removed)\n",
    "\n",
    "#### Instructor information\n",
    "\n",
    "The goals for this part of the exam are for students to do the following:\n",
    "\n",
    "1. Perform a train-test split of data\n",
    "2. Answer conceptual questions about the data using some of the terminology using in ML (e.g. what are features? what are labels? what are samples? etc.)\n",
    "3. Fit an SVM classifier to training data and then run a prediction on testing data\n",
    "4. Interpret the outputs of the classification report and confusion matrix.\n",
    "\n",
    "This component of the exam should mirror what they were expected to do in Homework 4, but pulling in PCA is probably not necessarily unless it's well-scaffolded and is fairly straightforward to do with the data... Also, it probably doesn't make sense to do anything with the Perceptron model for the purposes of the exam. And, again, **make sure this works on JupyterHub**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will use a support vector machine (SVM) classifier to identify seed varieties based on various seed measurements. We will be using the UC Irvine Machine Learning Repository Seeds Dataset. More info about this dataset can be found here https://archive.ics.uci.edu/dataset/236/seeds. \n",
    "\n",
    "To get started, download the `Seeds.csv` file from the link below (or D2L) and place it in the same directory as your notebook. \n",
    "\n",
    "`https://raw.githubusercontent.com/skarnik1337/cmse202sec002s24final/main/Seeds.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.1 (2 points)**: Read in the `Seeds.csv` dataset into a `Pandas` `DataFrame` and display the first and last few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 3.1 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "import pandas as pd\n",
    "\n",
    "seeds_path = './data/'\n",
    "seeds_file_name = 'Seeds.csv'\n",
    "\n",
    "seeds_df = pd.read_csv(os.path.join(seeds_path, seeds_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.2 (2 points)**: Our goal is to classify the `Variety` of the seed given the features `Area`, `Perimeter`, `Compactness`, `Kernel Length`, `Kernel Width`, `Asymmerty` and `Groove Length`. Create a variable with all of the columns of the `DataFrame` except for `Variety`,  and another variable with just the `Variety` column of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 3.2 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "seed_features = seeds_df.drop(columns=['Variety'])\n",
    "seed_labels = seeds_df['Variety']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is properly loaded into Python, we need to perform a **train-test-split** so that we can build our SVM classifier and test it.\n",
    "\n",
    "&#9989; **Question 3.3 (4 points)**: Use the `train_test_split()` method from `sklearn.model_selection` like we did in class. Use a `train_size` of `0.75` and `random_state` of `161803`. You should now have training features, testing features, training labels, and testing labels. Finally, **print the shape of your training features, training labels, testing features, and testing labels** to verify that your train-test-split did what it was supposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 3.3 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(seed_features, seed_labels, train_size=0.75, random_state=161803)\n",
    "print(features_train.shape)\n",
    "print(labels_train.shape)\n",
    "print(features_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.4 (6 points)**: Fit an SVM classifier (using the `sklearn` `SVC` class) to the dataset. Use a `linear` kernel and set the hyper-parameter to be `C=0.001.` Then **fit the SVM using your training set** and use the resulting SVM to **predict the labels for the testing set** so you get predicted labels for the testing set. Finally, **print the fit statistics** using the `confusion_matrix()` and `classification_report()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 3.4 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='linear', C=0.001)\n",
    "svc.fit(features_train, labels_train)\n",
    "\n",
    "labels_predict = svc.predict(features_test)\n",
    "\n",
    "print(confusion_matrix(labels_test,labels_predict))\n",
    "print(classification_report(labels_test,labels_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.5 (2 points)**: Create a second SVM classifier and test it by repeating your work from Question 4.4, but this time set the hyper-parameter to be `C=100.` Again, **print the fit statistics** using the `confusion_matrix()` and `classification_report()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 3.5 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "svc2 = SVC(kernel='linear', C=100)\n",
    "svc2.fit(features_train, labels_train)\n",
    "\n",
    "labels_predict2 = svc2.predict(features_test)\n",
    "\n",
    "print(confusion_matrix(labels_test,labels_predict2))\n",
    "print(classification_report(labels_test,labels_predict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.6 (6 points)**: Interpret the outputs of your classification reports and the confusion matrices by answering these questions (provide at least a couple sentences each for full credit): \n",
    "\n",
    "* Of the 53 seeds in the testing set, how many were misclassified by the first SVM (`C = 0.001`)? How many were misclassified by the second SVM (`C = 100`)? **Explain how you figured out the number of misclassifications**. \n",
    "\n",
    "* For just the first SVM (`C = 0.001`) what were the **precision** and **recall** for just the `Canadian` class? Explain in complete sentences what both of these numbers mean **in the context of this dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "* The first SVM had $14+1+2 = 17$ misclassifications while the second SVM had $1+2 = 3$ misclassifications. This is figured out by adding the off-diagonal elements in the confusion matrix.\n",
    "\n",
    "* For the first classifier, the precision for `Canadian` seeds was $1.00$, and the recall for `Canadian` seeds was $0.30$. A precision of $1.00$ means that every seed that was classified as `Canadian` was actually a `Canadian` seed. A recall of $0.30$ means that $30\\%$ of `Canadian` seeds were correctly classified as a `Canadian` seed.\n",
    "\n",
    "(Students might have slightly different results if they did their train-test-split differently or have a different version of Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "&#9989; **Question 3.7 (1 point)**: Suppose we wanted to try fitting a Support Vector Classifier for multiple choices of the kernel function and multiple choices for the values of the hyperparameter(s) (instead of just using a `linear` kernel with one value of `C`). We could write code with nested for loops to repeat the procedure with every combination of kernel function and hyperparameter value(s) we wanted to try. Name a method built into sklearn that will do this automatically. (We used this on an in-class assignment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "sklearn.model_selection.GridSearchCV or just GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.8 (3 points)**: Both of the images below show the same two-dimensional dataset with two classes (solid blue squares and unfilled red circles) along with the decision boundary of a linear classifier. One classifier was generated via the Perceptron Learning Algorithm, and the other used a Support Vector Classifier. Which one is which? **Justify your answer!**\n",
    "\n",
    "Classifier A          | | Classifier B\n",
    ":-------------------------:|:---:|:-------------------------:\n",
    "![](https://i.ibb.co/R2BBsDC/Datapoints1-A.png)  | |  ![](https://i.ibb.co/mb9vcq4/Datapoints1-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> **Do This - Erase the contents of this cell an put your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "Classifier A (left) used the PLA while Classifier B (right) used SVC. Both classifiers have zero errors, but Classifier B has a larger margin. Hence, Classifier A cannot be the SVC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.9 (3 points)**: Both of the images below show the same two-dimensional dataset with two classes (solid blue squares and unfilled red circles) along with the decision boundary of a linear Support Vector Classifier. One used the hyperparameter `C = 0.1`, and the other used the hyperparameter `C = 1000`. Which one is which? **Justify your answer!**\n",
    "\n",
    "Classifier X          | | Classifier Y\n",
    ":-------------------------:|:---:|:-------------------------:\n",
    "![](https://i.ibb.co/7pPCRwh/Datapoints2-A.png)  | |  ![](https://i.ibb.co/LSMBXzd/Datapoints2-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ANSWER\n",
    "\n",
    "Classifier X (left) used `C=1000` while Classifier Y (right) used `C=0.1`. Classifier X found a line with a small margin, but no misclassifications, i.e. it overfit the data. Classifier Y found a line with a bigger margin but some violations of this margin. Hence, Classifier X used a larger value of C to heavily penalize violating the margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 4: Logistic Regression Classification (12 points)\n",
    "\n",
    "The data for this part comes from the medical field, and it aims to fit a logisitic regression model that will predict whether an individual is likely to have diabetes or not based on a variety of predictor variables. See the file `diabetes_readme.txt` for more details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 (2 pts) Load the file `diabetes.csv` into a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "import os\n",
    "\n",
    "data_path = './data/'\n",
    "diabetes_file_name = 'diabetes.csv'\n",
    "\n",
    "df_diabetes = pd.read_csv(os.path.join(data_path, diabetes_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 (3 pts) Split the dataset into training (75%) and testing (25%). \n",
    "\n",
    "Use the columns ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker','Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'HvyAlcoholConsump',\n",
    "       'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'Sex', 'Age', 'Income'] as your predictors, and the column 'Diabetes_binary' as your outcome variable. \n",
    "\n",
    "**Hint: Do not forget to add a constant to the feature vector using sm.add_constant()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "X = df_diabetes[['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker','Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'HvyAlcoholConsump',\n",
    "                'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'Sex', 'Age', 'Income']]\n",
    "X = sm.add_constant(X)\n",
    "y = df_diabetes['Diabetes_binary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 (3 pts) Use statsmodels to train a logistic classification model, and print the summary table of the logit regression results.\n",
    "\n",
    "**Hint: Do not forget to include the constant term to your training vector using sm.add_constant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "logit_model = sm.Logit(y_train, X_train)\n",
    "logit_result = logit_model.fit()\n",
    "print(logit_result.summary() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 (2 pts) Use the .predict() method to create the predicted labels using the test input. Print the output.\n",
    "\n",
    "**Hint: the predicted output must be either 0 (no diabetes) or 1 (diabetes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "# get predicted values\n",
    "y_pred = logit_result.predict(X_test)\n",
    "\n",
    "# round them so theyre are either 0 or 1\n",
    "y_pred = np.round(y_pred)\n",
    "\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 (2 pts) Use sklearn.metrics to obtain and print the accuracy_score on the 0/1 predicted versus test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANSWER\n",
    "\n",
    "# Classification accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(accuracy) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Exam!\n",
    "\n",
    "Upload a copy of this notebook to the dropbox on D2L, and check in with instructional team before leaving the room."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
